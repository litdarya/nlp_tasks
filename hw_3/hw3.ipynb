{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "## Text Normalization \n",
    "\n",
    "deadline: 15 мая 2020, 23:30\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом соревнования по нормализации текстов на русском языке. \n",
    "\n",
    "Ссылка на соревнование:\n",
    "https://www.kaggle.com/c/text-normalization-challenge-russian-language\n",
    "\n",
    "Корпус (train-test split) доступен там же, на kaggle. Кроме того, kaggle проверяет результаты на тестовом множестве. Пример сабмита в файле: ru_sample_submission_2. \n",
    "\n",
    "Задача заключается в том, привести исходный текст (колонку before) в нормализованную форму (колонка after). Дополнительно известны классы токенов (колонка class), общее число классов – 15. В тестовом множестве классы токенов отсутствуют. \n",
    "\n",
    "Корпус состоит из предложений на русском языке и их нормализованных аналогов. Примеры продемонстрированы на kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание сдается через anytask, инвайты будут дополнительно высланы.\n",
    "3. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "4. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "5. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "6. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "7. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = 'darlitlit'\n",
    "os.environ['KAGGLE_KEY'] = 'dcc30c94bda5fb17c97cc9d0f6c8e407'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading text-normalization-challenge-russian-language.zip to /home/ulyanin/jupyter-notebook/nlp_tasks/hw_3\n",
      " 93%|█████████████████████████████████████   | 111M/120M [00:02<00:00, 39.5MB/s]\n",
      "100%|████████████████████████████████████████| 120M/120M [00:02<00:00, 56.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c text-normalization-challenge-russian-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip text-normalization-challenge-russian-language.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. [1 балл] Эксплоративный анализ\n",
    "\n",
    "1. Найдите примеры каждого класса и опишите, по какой логике проведена нормализация токенов разных классов. \n",
    "2. В каких случаях токены класса PLAIN подвергаются нормализации? \n",
    "3. Напишите правила для нормализации токенов класса ORDINAL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. [6 баллов]  seq2seq архитектуры\n",
    "Имплементируйте несколько seq2seq архитектур. Энкодер получает на вход последовательность токенов before, декодер учится превращать их в токены after.\n",
    "Энкодер и декодер работают на уровне символов, эмбеддинги символов инициализируются случайно (по аналогии с работами, в которых предложены нейросетевые модели исправления опечаток).\n",
    "\n",
    "Эту часть задания рекомендуется выполнять с использованием allennlp (должно быть проще и удобнее).\n",
    "\n",
    "1. [3 балла] LSTM encoder + LSTM decoder + три механизма внимания: скалярное произведение, аддитивное внимание и мультипликативное внимание (см. лекцию 6, слайд \"подсчет весов attention\")\n",
    "2. [3 балла] Transformer\n",
    "\n",
    "Используя автопровереку kaggle, оцените, как влияют параметры архитектуры на качество задачи.\n",
    "\n",
    "[бонус] convolutional encoder + convolutional decoder\n",
    "\n",
    "[бонус] pyramid LSTM (размер l+1 слоя в два раз меньше размера l, i-тый вход l+1 слоя – конкатенация выходов 2i и 2i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. [2 балла]  Дополнительные признаки\n",
    "Предложите и покажите, как можно было бы повысить качество нейросетевых моделей. Примерные варианты:\n",
    "1. ансамблирование нейронных сетей\n",
    "2. добавление морфологоческих признаков \n",
    "3. использование эмбеддингов слов \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Проведите анализ ошибок: когда модель ошибается? Можно ли скзаать, почему модель ошибается? Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Эксплоративный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Найдите примеры каждого класса и опишите, по какой логике проведена нормализация токенов разных классов. \n",
    "2. В каких случаях токены класса PLAIN подвергаются нормализации? \n",
    "3. Напишите правила для нормализации токенов класса ORDINAL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('ru_train.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>По</td>\n",
       "      <td>По</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>состоянию</td>\n",
       "      <td>состоянию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>на</td>\n",
       "      <td>на</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DATE</td>\n",
       "      <td>1862 год</td>\n",
       "      <td>тысяча восемьсот шестьдесят второй год</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  class     before  \\\n",
       "0            0         0  PLAIN         По   \n",
       "1            0         1  PLAIN  состоянию   \n",
       "2            0         2  PLAIN         на   \n",
       "3            0         3   DATE   1862 год   \n",
       "4            0         4  PUNCT          .   \n",
       "\n",
       "                                    after  \n",
       "0                                      По  \n",
       "1                               состоянию  \n",
       "2                                      на  \n",
       "3  тысяча восемьсот шестьдесят второй год  \n",
       "4                                       .  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('ru_test.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Производится</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Азии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Африке</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id        before\n",
       "0            0         0  Производится\n",
       "1            0         1             в\n",
       "2            0         2          Азии\n",
       "3            0         3             ,\n",
       "4            0         4        Африке"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examples = pd.read_csv('ru_sample_submission_2.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>Эта</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>книга</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>отличающаяся</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>«</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         after\n",
       "0  0_0           Эта\n",
       "1  0_1         книга\n",
       "2  0_2             ,\n",
       "3  0_3  отличающаяся\n",
       "4  0_4             «"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Найдите примеры каждого класса и опишите, по какой логике проведена нормализация токенов разных классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = list(set(train_df['class'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before    after    class\n",
      "--------  -------  -------\n",
      ")         )        PUNCT\n",
      ",         ,        PUNCT\n",
      ")         )        PUNCT\n",
      ".         .        PUNCT\n",
      ")         )        PUNCT\n",
      ")         )        PUNCT\n",
      "«         «        PUNCT\n",
      ".         .        PUNCT\n",
      ",         ,        PUNCT\n",
      ".         .        PUNCT\n",
      "before    after    class\n",
      "--------  -------  --------\n",
      "-         -        VERBATIM\n",
      "-         -        VERBATIM\n",
      "Β         бета     VERBATIM\n",
      "-         -        VERBATIM\n",
      "-         -        VERBATIM\n",
      "-         -        VERBATIM\n",
      "-         -        VERBATIM\n",
      "-         -        VERBATIM\n",
      "店        店       VERBATIM\n",
      "ր         ր        VERBATIM\n",
      "  before  after                    class\n",
      "--------  -----------------------  -------\n",
      "    0185  ноль один восемь пять    DIGIT\n",
      "      06  ноль шесть               DIGIT\n",
      "    0941  ноль девять четыре один  DIGIT\n",
      "      07  ноль семь                DIGIT\n",
      "      06  ноль шесть               DIGIT\n",
      "     000  ноль ноль ноль           DIGIT\n",
      "    0341  ноль три четыре один     DIGIT\n",
      "    0966  ноль девять шесть шесть  DIGIT\n",
      "     001  ноль ноль один           DIGIT\n",
      "      04  ноль четыре              DIGIT\n",
      "before     after                                                      class\n",
      "---------  ---------------------------------------------------------  -------\n",
      "9А         девять ампер                                               MEASURE\n",
      "52,6 км².  пятьдесят две целых и шесть десятых квадратного километра  MEASURE\n",
      "85 км/ч.   восемьдесят пять километров в час                          MEASURE\n",
      "2 т.       две тонны                                                  MEASURE\n",
      "9 %        девять процентов                                           MEASURE\n",
      "48 с       сорок восемь секунд                                        MEASURE\n",
      "480 мм.    четырехсот восьмидесяти миллиметров                        MEASURE\n",
      "18 т.      восемнадцати тоннах                                        MEASURE\n",
      "700 с.     семьсот секунд                                             MEASURE\n",
      "68 с.      шестьдесят восемь секунд                                   MEASURE\n",
      "before             after                                                                                                                  class\n",
      "-----------------  ---------------------------------------------------------------------------------------------------------------------  ---------\n",
      "5-17-023468-6      пять sil семнадцать sil ноль двести тридцать четыре шестьдесят восемь sil шесть                                        TELEPHONE\n",
      "(8)10              восемь sil десять                                                                                                      TELEPHONE\n",
      "5-93165-160-8      пять sil девятьсот тридцать один шестьдесят пять sil сто шестьдесят sil восемь                                         TELEPHONE\n",
      "1917-1980          девятнадцать семнадцать sil девятнадцать восемьдесят                                                                   TELEPHONE\n",
      "1923-1996          девятнадцать двадцать три sil девятнадцать девяносто шесть                                                             TELEPHONE\n",
      "1990-1995          девятнадцать девяносто sil девятнадцать девяносто пять                                                                 TELEPHONE\n",
      "5-86153-055-6      пять sil восемьсот шестьдесят один пятьдесят три sil ноль пятьдесят пять sil шесть                                     TELEPHONE\n",
      "978-5-91419-854-8  девятьсот семьдесят восемь sil пять sil девятьсот четырнадцать девятнадцать sil восемьсот пятьдесят четыре sil восемь  TELEPHONE\n",
      "3-484-22005-8      три sil четыреста восемьдесят четыре sil два два ноль ноль пять sil восемь                                             TELEPHONE\n",
      "0-471-48679-5      ноль sil четыреста семьдесят один sil четыреста восемьдесят шесть семьдесят девять sil пять                            TELEPHONE\n",
      "before    after    class\n",
      "--------  -------  -------\n",
      "К.        к        LETTERS\n",
      "НСК       н с к    LETTERS\n",
      "А. М.     а м      LETTERS\n",
      "Св        с в      LETTERS\n",
      "РВК       р в к    LETTERS\n",
      "А. С.     а с      LETTERS\n",
      "НГПУ      н г п у  LETTERS\n",
      "РФ        р ф      LETTERS\n",
      "БГУ       б г у    LETTERS\n",
      "ФГИС      ф г и с  LETTERS\n",
      "before       after                                                                            class\n",
      "-----------  -------------------------------------------------------------------------------  -------\n",
      "gadgarrense  г_trans а_trans д_trans г_trans а_trans р_trans р_trans е_trans н_trans з_trans  PLAIN\n",
      "карри        карри                                                                            PLAIN\n",
      "выступлений  выступлений                                                                      PLAIN\n",
      "Свифт        Свифт                                                                            PLAIN\n",
      "панк         панк                                                                             PLAIN\n",
      "Совета       Совета                                                                           PLAIN\n",
      "пять         пять                                                                             PLAIN\n",
      "медиафайлы   медиафайлы                                                                       PLAIN\n",
      "могут        могут                                                                            PLAIN\n",
      "и            и                                                                                PLAIN\n",
      "before        after                                                    class\n",
      "------------  -------------------------------------------------------  -------\n",
      "12 тысяч      двенадцати тысяч                                         DECIMAL\n",
      "2,18          двух целых и восемнадцати сотых                          DECIMAL\n",
      "50 миллионов  пятидесяти миллионов                                     DECIMAL\n",
      "5763,6        пять тысяч семьсот шестьдесят три целых и шесть десятых  DECIMAL\n",
      "2,8           две целых и восемь десятых                               DECIMAL\n",
      "10 млн        десяти миллионов                                         DECIMAL\n",
      "150 тыс.      сто пятьдесят тысяч                                      DECIMAL\n",
      "245,5         двести сорок пять целых и пять десятых                   DECIMAL\n",
      "1,8 млн       одной целой и восьми десятых миллиона                    DECIMAL\n",
      "111,1         сто одиннадцать целых и одна десятая                     DECIMAL\n",
      "before    after                               class\n",
      "--------  ----------------------------------  -------\n",
      "XIX       девятнадцатом                       ORDINAL\n",
      "5-го      пятого                              ORDINAL\n",
      "1980-х    тысяча девятьсот восьмидесятых      ORDINAL\n",
      "3-м       третьем                             ORDINAL\n",
      "3-х       третьих                             ORDINAL\n",
      "1961      тысяча девятьсот шестьдесят первом  ORDINAL\n",
      "—1980     тысяча девятьсот восьмидесятом      ORDINAL\n",
      "—1936     тысяча девятьсот тридцать шестом    ORDINAL\n",
      "VIII      восьмой                             ORDINAL\n",
      "2-е       вторые                              ORDINAL\n",
      "before         after                                                                            class\n",
      "-------------  -------------------------------------------------------------------------------  --------\n",
      "2013/14        две тысячи тринадцать четырнадцатых                                              FRACTION\n",
      "1282/1283      тысяча двести восемьдесят две тысяча двести восемьдесят третьих                  FRACTION\n",
      "3 1/93         три целых и одну девяносто третью                                                FRACTION\n",
      "1007/10542753  тысяча семь десять миллионов пятьсот сорок две тысячи семьсот пятьдесят третьих  FRACTION\n",
      "871/873        восемьсот семьдесят одна восемьсот семьдесят третья                              FRACTION\n",
      "9/11           девять одиннадцатых                                                              FRACTION\n",
      "16/17          шестнадцать семнадцатых                                                          FRACTION\n",
      "1/8            одна восьмая                                                                     FRACTION\n",
      "2013/2014      двух тысяч тринадцати две тысячи четырнадцатых                                   FRACTION\n",
      "2013/14        две тысячи тринадцать четырнадцатых                                              FRACTION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before            after                                                                                                        class\n",
      "----------------  -----------------------------------------------------------------------------------------------------------  ----------\n",
      "vishime.ru        в_trans и_trans ш_trans и_trans м_trans точка р_trans у_trans                                                ELECTRONIC\n",
      "tolweb.org        т_trans о_trans л_trans у_trans э_trans б_trans точка о_trans р_trans г_trans                                ELECTRONIC\n",
      "Shakira.com       ш_trans е_trans й_trans к_trans и_trans р_trans а_trans точка к_trans о_trans м_trans                        ELECTRONIC\n",
      "OM.net            о_trans м_trans точка н_trans е_trans т_trans                                                                ELECTRONIC\n",
      "Sportal.bg        с_trans п_trans о_trans р_trans т_trans а_trans л_trans точка b g                                            ELECTRONIC\n",
      "www.enric.es      w w w точка э_trans н_trans р_trans и_trans к_trans точка e s                                                ELECTRONIC\n",
      "Ibnlive.in.com    и_trans б_trans н_trans л_trans а_trans й_trans в_trans точка и_trans н_trans точка к_trans о_trans м_trans  ELECTRONIC\n",
      "Salon.com         с_trans а_trans л_trans о_trans н_trans точка к_trans о_trans м_trans                                        ELECTRONIC\n",
      "Itunes.apple.com  и_trans ч_trans у_trans н_trans с_trans точка э_trans п_trans л_trans точка к_trans о_trans м_trans          ELECTRONIC\n",
      "наградами.doc     н а г р а д а м и точка д_trans о_trans к_trans                                                              ELECTRONIC\n",
      "before             after                                                  class\n",
      "-----------------  -----------------------------------------------------  -------\n",
      "6 ноября 2013      шестого ноября две тысячи тринадцатого года            DATE\n",
      "2000 года          двух тысячного года                                    DATE\n",
      "9 марта 1937 года  девятое марта тысяча девятьсот тридцать седьмого года  DATE\n",
      "3 февраля 2012     третьего февраля две тысячи двенадцатого года          DATE\n",
      "2001 года          две тысячи первого года                                DATE\n",
      "1957 гг.           тысяча девятьсот пятьдесят седьмой год                 DATE\n",
      "1932 году          тысяча девятьсот тридцать втором году                  DATE\n",
      "1923 году          тысяча девятьсот двадцать третьем году                 DATE\n",
      "1949 году          тысяча девятьсот сорок девятом году                    DATE\n",
      "20 июля            двадцатого июля                                        DATE\n",
      "before               after                                                            class\n",
      "-------------------  ---------------------------------------------------------------  -------\n",
      "1300 рублей          тысячи трехсот рублей                                            MONEY\n",
      "€18 млн              восемнадцать миллионов евро                                      MONEY\n",
      "4 миллиона долларов  четыре миллиона долларов                                         MONEY\n",
      "$30 млн.             тридцати миллионов долларов сэ ш а                               MONEY\n",
      "612 долларов         шестьсот двенадцать долларов                                     MONEY\n",
      "6000 песо            шесть тысяч аргентинских песо                                    MONEY\n",
      "68 125 долларов      шестьдесят восемь тысяч сто двадцать пять долларов               MONEY\n",
      "$116,4 млн.          сто шестнадцать целых и четыре десятых миллиона долларов сэ ш а  MONEY\n",
      "$ 50 млн             пятидесяти миллионов долларов сэ ш а                             MONEY\n",
      "1,7 млрд руб.        одна целая и семь десятых миллиарда рублей                       MONEY\n",
      "before    after                                  class\n",
      "--------  -------------------------------------  -------\n",
      "6:15      шесть часов пятнадцать минут           TIME\n",
      "12:00     двенадцать часов                       TIME\n",
      "16:25     шестнадцать часов двадцать пять минут  TIME\n",
      "15:12     пятнадцать часов двенадцать минут      TIME\n",
      "10:23     десять часов двадцать три минуты       TIME\n",
      "10:34     десять часов тридцать четыре минуты    TIME\n",
      "16:14     шестнадцать часов четырнадцать минут   TIME\n",
      "7:15      семь часов пятнадцать минут            TIME\n",
      "3:48      три часа сорок восемь минут            TIME\n",
      "10:15     десять часов пятнадцать минут          TIME\n",
      "before    after                            class\n",
      "--------  -------------------------------  --------\n",
      "II        два                              CARDINAL\n",
      "166       ста шестидесяти шести            CARDINAL\n",
      "1863      тысяча восемьсот шестьдесят три  CARDINAL\n",
      "2         два                              CARDINAL\n",
      "165       сто шестьдесят пять              CARDINAL\n",
      "9         девять                           CARDINAL\n",
      "2001      двух тысячах одном               CARDINAL\n",
      "60        шестьдесят                       CARDINAL\n",
      "1992      тысяча девятьсот девяносто два   CARDINAL\n",
      "-30       минус тридцать                   CARDINAL\n"
     ]
    }
   ],
   "source": [
    "n_examples = 10\n",
    "for cls in CLS:\n",
    "    idx = train_df['class'] == cls\n",
    "    examples = train_df[idx].sample(n_examples)\n",
    "    print(tabulate(examples[['before', 'after', 'class']],\n",
    "                   headers=['before', 'after', 'class'],\n",
    "                   showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'PUNCT' -- знаки пунктуация, никак не меняются\n",
    "\n",
    "'VERBATIM' -- как вслух произносится символ (\"в квадрате\", \"нижнее подчеркивание\", буквы греческого алфавита)\n",
    "\n",
    "'DIGIT' -- числа\n",
    "\n",
    "'MEASURE' -- как вслух произносятся сокращения для единиц измерения\n",
    "\n",
    "'TELEPHONE' -- телефон, вместо - ставится sil\n",
    "\n",
    "'LETTERS' -- пробелом разделяются аббревиатуры\n",
    "\n",
    "'PLAIN' -- слова, написанные на русском, не меняются, иначе -- транскрибируются\n",
    "\n",
    "'DECIMAL' -- числа, дробные и с сокращениями (тыс, млн)\n",
    "\n",
    "'ORDINAL' -- порядковые числительные\n",
    "\n",
    "'FRACTION' -- дроби\n",
    "\n",
    "'ELECTRONIC' -- как произносятся ссылки (транскрипция)\n",
    "\n",
    "'DATE' -- даты\n",
    "\n",
    "'MONEY' -- числа и валютные названия (транскрипцией, сша -- сэ ш а)\n",
    "\n",
    "'TIME' -- время\n",
    "\n",
    "'CARDINAL' -- числа в именительном падеже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## В каких случаях токены класса PLAIN подвергаются нормализации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Tiberius</td>\n",
       "      <td>т_trans и_trans б_trans е_trans р_trans и_tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Julius</td>\n",
       "      <td>д_trans ж_trans у_trans л_trans и_trans у_tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Pollienus</td>\n",
       "      <td>п_trans о_trans л_trans л_trans и_trans е_tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Auspex</td>\n",
       "      <td>о_trans с_trans п_trans е_trans к_trans с_trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Half</td>\n",
       "      <td>х_trans а_trans л_trans ф_trans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  token_id  class     before  \\\n",
       "43             3         7  PLAIN   Tiberius   \n",
       "44             3         8  PLAIN     Julius   \n",
       "45             3         9  PLAIN  Pollienus   \n",
       "46             3        10  PLAIN     Auspex   \n",
       "153           10         4  PLAIN       Half   \n",
       "\n",
       "                                                 after  \n",
       "43   т_trans и_trans б_trans е_trans р_trans и_tran...  \n",
       "44   д_trans ж_trans у_trans л_trans и_trans у_tran...  \n",
       "45   п_trans о_trans л_trans л_trans и_trans е_tran...  \n",
       "46     о_trans с_trans п_trans е_trans к_trans с_trans  \n",
       "153                    х_trans а_trans л_trans ф_trans  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain = train_df[train_df['class'] == 'PLAIN']\n",
    "plain[plain.before != plain.after].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'PLAIN' нормализуются (транслитерируются), если написаны нерусскими буквами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Напишите правила для нормализации токенов класса ORDINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>III</td>\n",
       "      <td>третьего</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>1895</td>\n",
       "      <td>тысяча восемьсот девяносто пятом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>—1896</td>\n",
       "      <td>тысяча восемьсот девяносто шестом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>1796</td>\n",
       "      <td>тысяча семьсот девяносто шестого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>1802</td>\n",
       "      <td>тысяча восемьсот второй</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id  token_id    class before                              after\n",
       "53             3        17  ORDINAL    III                           третьего\n",
       "163           11         1  ORDINAL   1895   тысяча восемьсот девяносто пятом\n",
       "164           11         2  ORDINAL  —1896  тысяча восемьсот девяносто шестом\n",
       "485           35         5  ORDINAL   1796   тысяча семьсот девяносто шестого\n",
       "487           35         7  ORDINAL   1802            тысяча восемьсот второй"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal = train_df[train_df['class'] == 'ORDINAL']\n",
    "ordinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_ordinals = list(set(ordinal['sentence_id'].values))\n",
    "with_ordinals = train_df[train_df['sentence_id'].isin(with_ordinals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_df = with_ordinals.groupby(['sentence_id'])['before'].apply(list)\n",
    "after_df = with_ordinals.groupby(['sentence_id'])['after'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_df = pd.DataFrame({'text': before_df}).reset_index()\n",
    "before_df = before_df.text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_df = pd.DataFrame({'text': after_df}).reset_index()\n",
    "after_df = after_df.text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Тиберий Юлий Поллиен Ауспекс ( лат . Tiberius ...\n",
       "1        в 1895 —1896 годах служил на Черноморском флот...\n",
       "2        После Павловских реформ , с 1796 по 1802 год ,...\n",
       "3        Некоторые источники указывают на период 1109 —...\n",
       "4        Джон Стюарт , 1-й маркиз Бьют , стал носить эт...\n",
       "                               ...                        \n",
       "33236    Сформирована 21 апреля 1944 года путем преобра...\n",
       "33237    Соответственно отодвигался и ввод в прорыв 6-г...\n",
       "33238    В первом тайме на 7-й минуте Зинедин Зидан реа...\n",
       "33239    Packard Station Sedan — это легковой автомобил...\n",
       "33240    В отличие от зенитных артиллерийских полков в ...\n",
       "Name: text, Length: 33241, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. [6 баллов]  seq2seq архитектуры\n",
    "Имплементируйте несколько seq2seq архитектур. Энкодер получает на вход последовательность токенов before, декодер учится превращать их в токены after.\n",
    "Энкодер и декодер работают на уровне символов, эмбеддинги символов инициализируются случайно (по аналогии с работами, в которых предложены нейросетевые модели исправления опечаток).\n",
    "\n",
    "Эту часть задания рекомендуется выполнять с использованием allennlp (должно быть проще и удобнее).\n",
    "\n",
    "1. [3 балла] LSTM encoder + LSTM decoder + три механизма внимания: скалярное произведение, аддитивное внимание и мультипликативное внимание (см. лекцию 6, слайд \"подсчет весов attention\")\n",
    "2. [3 балла] Transformer\n",
    "\n",
    "Используя автопровереку kaggle, оцените, как влияют параметры архитектуры на качество задачи.\n",
    "\n",
    "[бонус] convolutional encoder + convolutional decoder\n",
    "\n",
    "[бонус] pyramid LSTM (размер l+1 слоя в два раз меньше размера l, i-тый вход l+1 слоя – конкатенация выходов 2i и 2i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM encoder + LSTM decoder + три механизма внимания: скалярное произведение, аддитивное внимание и мультипликативное внимание (см. лекцию 6, слайд \"подсчет весов attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скалярное произведение -- allennlp.modules.attention.dot_product_attention.DotProductAttention\n",
    "\n",
    "\n",
    "Аддитивное внимание -- allennlp.modules.attention.additive_attention.AdditiveAttention\n",
    "\n",
    "\n",
    "Мультипликативное внимание -- allennlp.modules.attention.bilinear_attention.BilinearAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
    "from allennlp.modules.attention import LinearAttention\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.data.tokenizers.character_tokenizer import CharacterTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.token_indexers import TokenCharactersIndexer\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.fields import TextField, SequenceLabelField\n",
    "from allennlp.data import Instance\n",
    "\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "import torch.optim as optim\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_df = train_df.groupby(['sentence_id'])['after'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_df.head()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_df = pd.DataFrame({'text': sentence_df}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_df.text = sentence_df.text.apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_df.to_csv('after_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761436"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataReader(DatasetReader):\n",
    "    def __init__(self, tokenizer, source_token_indexers, target_token_indexers, max_rows=None):\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_token_indexers = source_token_indexers\n",
    "        self.target_token_indexers = target_token_indexers\n",
    "        self.max_rows = max_rows\n",
    "\n",
    "    def text_to_instance(self, input_tokens, target_tokens):\n",
    "        input_field = TextField(input_tokens, self.source_token_indexers)\n",
    "        target_field = TextField(target_tokens, self.target_token_indexers)\n",
    "\n",
    "        fields = {\"source_tokens\": input_field, \"target_tokens\": target_field}\n",
    "\n",
    "        return Instance(fields)\n",
    "    \n",
    "    def _get_sentences(self, data, column):\n",
    "        sentence_df = data.groupby(['sentence_id'])[column].apply(list)\n",
    "        sentence_df = pd.DataFrame({'text': sentence_df}).reset_index()\n",
    "        sentence_df.text = sentence_df.text.apply(lambda x: ' '.join(map(str, x)))\n",
    "        \n",
    "        return sentence_df\n",
    "    \n",
    "    def _read(self, before_path):\n",
    "        before = pd.read_csv('before_train.csv')\n",
    "        after = pd.read_csv('after_train.csv')\n",
    "        \n",
    "        i = 0\n",
    "        for text, norm_text in zip(before.text.values, after.text.values):\n",
    "            before_tokens = self.tokenizer.tokenize(text)\n",
    "            after_tokens = self.tokenizer.tokenize(norm_text)\n",
    "            yield self.text_to_instance(before_tokens, after_tokens)\n",
    "            i += 1\n",
    "            if self.max_rows and i >= self.max_rows:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_token_indexer =  {\n",
    "#     'tokens': \n",
    "#     TokenCharactersIndexer(character_tokenizer=tokenizer, min_padding_length=1, namespace='tokens')\n",
    "# }\n",
    "# target_token_indexer =  {\n",
    "#     'tokens':\n",
    "#     TokenCharactersIndexer(character_tokenizer=tokenizer, min_padding_length=1, namespace='target_tokens')\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_token_indexer =  {\n",
    "    'tokens': \n",
    "    SingleIdTokenIndexer(namespace='tokens')\n",
    "}\n",
    "target_token_indexer =  {\n",
    "    'tokens':\n",
    "    SingleIdTokenIndexer(namespace='target_tokens')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharacterTokenizer(byte_encoding=None, lowercase_characters=True,\n",
    "                               start_tokens=['<sos>'], end_tokens=['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761436it [04:49, 2630.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dr = MyDataReader(tokenizer, source_token_indexer, target_token_indexer)\n",
    "data_set = dr.read('before_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data_set = data_set[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t source_tokens: TextField of length 28 with text: \n",
      " \t\t[<sos>, п, о,  , с, о, с, т, о, я, н, и, ю,  , н, а,  , 1, 8, 6, 2,  , г, о, д,  , ., <eos>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t target_tokens: TextField of length 58 with text: \n",
      " \t\t[<sos>, п, о,  , с, о, с, т, о, я, н, и, ю,  , н, а,  , т, ы, с, я, ч, а,  , в, о, с, е, м, ь, с, о,\n",
      "\t\tт,  , ш, е, с, т, ь, д, е, с, я, т,  , в, т, о, р, о, й,  , г, о, д,  , ., <eos>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': <allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer at 0x7fa85d119290>}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0]['source_tokens']._token_indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from allennlp.data.dataset_readers.seq2seq import Seq2SeqDatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761437it [03:36, 3516.34it/s] \n"
     ]
    }
   ],
   "source": [
    "reader = Seq2SeqDatasetReader(\n",
    "        source_tokenizer=tokenizer,\n",
    "        target_tokenizer=tokenizer,\n",
    "        source_token_indexers={'tokens': SingleIdTokenIndexer()},\n",
    "        target_token_indexers={'tokens': SingleIdTokenIndexer(namespace='target_tokens')})\n",
    "_dataset = reader.read('before_train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t source_tokens: TextField of length 5 with text: \n",
      " \t\t[@start@, <sos>, 0, <eos>, @end@]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      " \t target_tokens: TextField of length 30 with text: \n",
      " \t\t[@start@, <sos>, п, о,  , с, о, с, т, о, я, н, и, ю,  , н, а,  , 1, 8, 6, 2,  , г, о, д,  , .,\n",
      "\t\t<eos>, @end@]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': <allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer at 0x7f9951480610>}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_dataset[0]['source_tokens']._token_indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bf = pd.read_csv('after_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentence_id', 'text'], dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bf.drop(columns=['Unnamed: 0', 'sentence_id']).to_csv('after_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761437it [02:36, 4876.07it/s] \n"
     ]
    }
   ],
   "source": [
    "# all_dataset = reader.read('before_train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761437it [03:46, 3365.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# all_dataset_y = reader.read('after_train.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set[0]['source_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 761436/761436 [01:04<00:00, 11725.76it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(data_set,\n",
    "                                  min_count={'source_tokens': 1,\n",
    "                                             'target_tokens': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary with namespaces:  tokens, Size: 131 || target_tokens, Size: 123 || Non Padded Namespaces: {'*labels', '*tags'}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = PytorchSeq2SeqWrapper(\n",
    "    torch.nn.LSTM(EN_EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = LinearAttention(HIDDEN_DIM, HIDDEN_DIM, activation=Activation.by_name('tanh')())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EN_EMBEDDING_DIM)\n",
    "\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_decoding_steps = 10\n",
    "ZH_EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(data_set)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76143.6"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(data_set, [len(data_set) - int(test_size),\n",
    "                                                              int(test_size)], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.dataset = train_set.dataset[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleSeq2Seq(vocab, word_embeddings, encoder, max_decoding_steps,\n",
    "                      target_embedding_dim=ZH_EMBEDDING_DIM,\n",
    "                      target_namespace='target_tokens',\n",
    "                      beam_size=8,\n",
    "                      use_bleu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "iterator = BucketIterator(batch_size=256, sorting_keys=[(\"source_tokens\", 'num_tokens')])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "unable to check gpu_memory_mb(), continuing\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ulyanin/jupyter-notebook/venv/lib/python3.7/site-packages/allennlp/common/util.py\", line 378, in gpu_memory_mb\n",
      "    encoding='utf-8')\n",
      "  File \"/usr/lib/python3.7/subprocess.py\", line 411, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/usr/lib/python3.7/subprocess.py\", line 488, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/usr/lib/python3.7/subprocess.py\", line 800, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/usr/lib/python3.7/subprocess.py\", line 1482, in _execute_child\n",
      "    restore_signals, start_new_session, preexec_fn)\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "loss: 3.6297 ||: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_set,\n",
    "                  validation_dataset=val_set,\n",
    "                  num_epochs=1)\n",
    "trainer.train()\n",
    "# for i in range(50):\n",
    "#     print('Epoch: {}'.format(i))\n",
    "    \n",
    "\n",
    "#     predictor = SimpleSeq2SeqPredictor(model, reader)\n",
    "\n",
    "#     for instance in itertools.islice(val_set, 10):\n",
    "#         print('SOURCE:', instance.fields['source_tokens'].tokens)\n",
    "#         print('GOLD:', instance.fields['target_tokens'].tokens)\n",
    "#         print('PRED:', predictor.predict_instance(instance)['predicted_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
