{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language\n",
    "\n",
    "*deadline*: 9 марта 2020, 23:30\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом Harry Potter and the Action Prediction Challenge. Корпус собран из фанфиков о Гарри Поттере и состоит из двух частей: 1) сырые тексты, 2) фрагменты текстов, описывающих ситуацию, в которой произнесено заклинание.\n",
    "\n",
    "Корпус описан в статье: https://arxiv.org/pdf/1905.11037.pdf\n",
    "\n",
    "David Vilares and Carlos Gómez-Rodríguez. Harry Potter and the Action Prediction Challenge from Natural Language. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics. To appear.\n",
    "\n",
    "Код для сбора корпуса находится в репозитории: https://github.com/aghie/hpac . Корпус можно скачать по инструкции из этого репозитория, но для экономии времени авторы задания уже скачали и подготовили данные к работе. \n",
    "\n",
    "Ссылки на собранный корпус: \n",
    "* Сырые тексты:  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "* Токенизированные тексты в нижнем регистре: https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "* train-test-dev: https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах (сырых или предобработанных -- на ваше усмотрение), Часть 3 – на разбиение на тестовое, отладочное и обучающее множества. Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание сдается через anytask, инвайты будут дополнительно высланы.\n",
    "3. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "4. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "5. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "6. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "7. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия. \n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 500-1000 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Читали ли вы сами Гарри Поттера или фанфики о нем и помогло ли вам знание предметной области в выполнении домашнего задания?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "Сырые тексты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !unzip hpac_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'hpac_raw': No such file or directory\r\n",
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!ls hpac_raw | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip hpac_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('hpac_corpus/hpac_training_128.tsv', sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7642954.0.676</td>\n",
       "      <td>RIDDIKULUS</td>\n",
       "      <td>were staring at her . she was up next to face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10443333.0.5753</td>\n",
       "      <td>RIDDIKULUS</td>\n",
       "      <td>that whole time . her first reaction , for whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4703706.0.8690</td>\n",
       "      <td>STUPEFY</td>\n",
       "      <td>we watched his inglorious withdrawal together ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4593427.0.1815</td>\n",
       "      <td>ACCIO</td>\n",
       "      <td>my wand , `` incendio . '' this wretched chill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4278446.0.2692</td>\n",
       "      <td>EXPELLIARMUS</td>\n",
       "      <td>already compared ours , they 're the same ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1  \\\n",
       "0    7642954.0.676    RIDDIKULUS   \n",
       "1  10443333.0.5753    RIDDIKULUS   \n",
       "2   4703706.0.8690       STUPEFY   \n",
       "3   4593427.0.1815         ACCIO   \n",
       "4   4278446.0.2692  EXPELLIARMUS   \n",
       "\n",
       "                                                   2  \n",
       "0  were staring at her . she was up next to face ...  \n",
       "1  that whole time . her first reaction , for whi...  \n",
       "2  we watched his inglorious withdrawal together ...  \n",
       "3  my wand , `` incendio . '' this wretched chill...  \n",
       "4  already compared ours , they 're the same ever...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RIDDIKULUS',\n",
       " \"were staring at her . she was up next to face the boggart in defense against the dark arts class . she was not scared , but what she was worried about was what had happened with lysander . she looked up at the boggart in front of her which had previously been a humongous spider . its eyes locked on her . before she could think of what frightened her , the spider transformed into lysander . he was dying . there were giggles coming from the male and female hufflepuff students . there was a smirk on lorcan 's face . `` lily help me '' i ca n't fail this class because of a secret love . lily lifted her wand and said , ``\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][1], df.iloc[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как использовать WordNet из nltk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ulyanin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# скачиваем WordNet\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('magic.n.01'), Synset('magic_trick.n.01'), Synset('charming.s.02')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слово -> множество синсетов (синонимов разных смыслов исходного слова)\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('magic_trick.n.01.magic_trick')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим, что внутри одного синсета\n",
    "wn.synsets('magic')[1].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deception'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем лемму одного из слов из синсета\n",
    "wn.synsets('magic')[1].lemmas()[-1].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Топ-1000 слов по частоте без учета стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "import pickle\n",
    "from  tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-19:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-24:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-37:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-42:\n",
      "Process ForkPoolWorker-43:\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-46:\n",
      "Process ForkPoolWorker-47:\n",
      "Process ForkPoolWorker-48:\n",
      "Process ForkPoolWorker-49:\n",
      "Process ForkPoolWorker-39:\n",
      "Process ForkPoolWorker-50:\n",
      "Process ForkPoolWorker-51:\n",
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-41:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "Process ForkPoolWorker-52:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "Process ForkPoolWorker-54:\n",
      "Process ForkPoolWorker-56:\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "Traceback (most recent call last):\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "Process ForkPoolWorker-55:\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "Process ForkPoolWorker-53:\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'lemmatize_sentence' on <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "global_pool = multiprocessing.Pool(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ulyanin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "RAW_TEXTS_DIR = 'fanfiction_texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bc41ccb726425d85ecd486955f6e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_count = defaultdict(int)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for path in tqdm(os.listdir(RAW_TEXTS_DIR)):\n",
    "    full_path = os.path.join(RAW_TEXTS_DIR, path)\n",
    "    with open(full_path, 'r') as f:\n",
    "        for line in f:\n",
    "            words = tokenizer.tokenize(line.strip())\n",
    "            for word in words:from t\n",
    "                word = word.lower()\n",
    "                if word not in STOPWORDS:\n",
    "                    word_count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('top_1000.pickle', 'wb') as f:\n",
    "#     pickle.dump(top_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_1000.pickle', 'rb') as f:\n",
    "    top_words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harry', 4000488),\n",
       " ('said', 2262364),\n",
       " ('hermione', 1831464),\n",
       " ('would', 1655264),\n",
       " ('back', 1400308),\n",
       " ('one', 1400054),\n",
       " ('draco', 1389966),\n",
       " ('could', 1303069),\n",
       " ('like', 1275300),\n",
       " ('know', 1203948),\n",
       " ('eyes', 1033469),\n",
       " ('time', 1016958),\n",
       " ('ron', 906181),\n",
       " ('looked', 893445),\n",
       " ('get', 847651),\n",
       " ('asked', 826495),\n",
       " ('well', 802448),\n",
       " ('even', 770242),\n",
       " ('around', 767637),\n",
       " ('see', 744540),\n",
       " ('head', 737080),\n",
       " ('going', 718863),\n",
       " ('think', 716079),\n",
       " ('still', 694767),\n",
       " ('go', 667647),\n",
       " ('face', 657549),\n",
       " ('way', 656362),\n",
       " ('severus', 655653),\n",
       " ('room', 648483),\n",
       " ('hand', 639610),\n",
       " ('ginny', 639543),\n",
       " ('sirius', 630217),\n",
       " ('something', 623393),\n",
       " ('want', 613213),\n",
       " ('potter', 608396),\n",
       " ('thought', 608149),\n",
       " ('right', 603543),\n",
       " ('snape', 600467),\n",
       " ('away', 580724),\n",
       " ('much', 578715),\n",
       " ('two', 572215),\n",
       " ('look', 566540),\n",
       " ('never', 559460),\n",
       " ('really', 526364),\n",
       " ('knew', 524840),\n",
       " ('first', 523467),\n",
       " ('made', 513183),\n",
       " ('let', 513130),\n",
       " ('good', 510087),\n",
       " ('malfoy', 486334),\n",
       " ('wand', 482517),\n",
       " ('little', 481391),\n",
       " ('felt', 476097),\n",
       " ('dumbledore', 472844),\n",
       " ('turned', 472763),\n",
       " ('james', 468947),\n",
       " ('come', 461147),\n",
       " ('got', 446945),\n",
       " ('make', 446018),\n",
       " ('took', 436164),\n",
       " ('remus', 433776),\n",
       " ('lily', 423882),\n",
       " ('though', 421472),\n",
       " ('sure', 414025),\n",
       " ('looking', 412947),\n",
       " ('say', 412107),\n",
       " ('door', 408796),\n",
       " ('tell', 407274),\n",
       " ('dark', 407087),\n",
       " ('take', 406712),\n",
       " ('us', 404371),\n",
       " ('long', 400953),\n",
       " ('voice', 397148),\n",
       " ('voldemort', 396693),\n",
       " ('last', 395133),\n",
       " ('told', 387987),\n",
       " ('need', 385193),\n",
       " ('left', 382492),\n",
       " ('yes', 381412),\n",
       " ('man', 378306),\n",
       " ('wanted', 369171),\n",
       " ('anything', 367354),\n",
       " ('next', 357422),\n",
       " ('oh', 355362),\n",
       " ('came', 343141),\n",
       " ('love', 341285),\n",
       " ('nodded', 341059),\n",
       " ('moment', 336220),\n",
       " ('people', 334999),\n",
       " ('year', 333338),\n",
       " ('saw', 333047),\n",
       " ('another', 332659),\n",
       " ('things', 328450),\n",
       " ('went', 325856),\n",
       " ('hands', 325015),\n",
       " ('death', 324143),\n",
       " ('help', 322672),\n",
       " ('day', 322607),\n",
       " ('enough', 320944),\n",
       " ('boy', 316913),\n",
       " ('smiled', 312584),\n",
       " ('professor', 311845),\n",
       " ('mind', 311632),\n",
       " ('nothing', 308573),\n",
       " ('ever', 308525),\n",
       " ('found', 306832),\n",
       " ('hair', 301575),\n",
       " ('always', 300553),\n",
       " ('house', 299252),\n",
       " ('find', 297437),\n",
       " ('bit', 296606),\n",
       " ('seemed', 293976),\n",
       " ('behind', 293761),\n",
       " ('hogwarts', 292077),\n",
       " ('thing', 287879),\n",
       " ('bed', 287639),\n",
       " ('trying', 284261),\n",
       " ('feel', 281511),\n",
       " ('put', 281299),\n",
       " ('started', 281286),\n",
       " ('life', 279701),\n",
       " ('since', 278135),\n",
       " ('black', 277103),\n",
       " ('night', 276927),\n",
       " ('heard', 273446),\n",
       " ('years', 269698),\n",
       " ('smile', 268328),\n",
       " ('without', 266676),\n",
       " ('side', 266635),\n",
       " ('better', 265331),\n",
       " ('magic', 263904),\n",
       " ('gave', 262515),\n",
       " ('might', 261477),\n",
       " ('weasley', 260521),\n",
       " ('everyone', 257575),\n",
       " ('father', 256195),\n",
       " ('sat', 254242),\n",
       " ('began', 253560),\n",
       " ('someone', 253201),\n",
       " ('almost', 252376),\n",
       " ('walked', 250456),\n",
       " ('done', 248115),\n",
       " ('finally', 247509),\n",
       " ('already', 246985),\n",
       " ('three', 246206),\n",
       " ('tried', 245227),\n",
       " ('place', 245212),\n",
       " ('every', 243955),\n",
       " ('stood', 242650),\n",
       " ('friends', 241073),\n",
       " ('everything', 240961),\n",
       " ('lord', 238907),\n",
       " ('front', 238700),\n",
       " ('small', 238338),\n",
       " ('pulled', 238162),\n",
       " ('also', 237641),\n",
       " ('quickly', 237230),\n",
       " ('course', 236434),\n",
       " ('body', 234851),\n",
       " ('girl', 234442),\n",
       " ('keep', 234441),\n",
       " ('best', 232186),\n",
       " ('towards', 228042),\n",
       " ('old', 224188),\n",
       " ('else', 223388),\n",
       " ('arms', 223093),\n",
       " ('neville', 221532),\n",
       " ('table', 221110),\n",
       " ('mean', 219659),\n",
       " ('give', 219635),\n",
       " ('work', 219427),\n",
       " ('family', 219201),\n",
       " ('sorry', 217530),\n",
       " ('albus', 216669),\n",
       " ('end', 215669),\n",
       " ('please', 215640),\n",
       " ('great', 215253),\n",
       " ('many', 214172),\n",
       " ('world', 214004),\n",
       " ('mother', 213938),\n",
       " ('school', 213614),\n",
       " ('lucius', 211132),\n",
       " ('together', 209583),\n",
       " ('new', 208980),\n",
       " ('stop', 208088),\n",
       " ('quite', 207916),\n",
       " ('happened', 206185),\n",
       " ('open', 206000),\n",
       " ('leave', 205871),\n",
       " ('maybe', 204900),\n",
       " ('replied', 204740),\n",
       " ('mouth', 203652),\n",
       " ('soon', 202643),\n",
       " ('must', 202614),\n",
       " ('yet', 202305),\n",
       " ('floor', 198391),\n",
       " ('later', 198083),\n",
       " ('getting', 196775),\n",
       " ('able', 195327),\n",
       " ('words', 194066),\n",
       " ('name', 193608),\n",
       " ('arm', 193454),\n",
       " ('hard', 193444),\n",
       " ('friend', 191664),\n",
       " ('lips', 191123),\n",
       " ('least', 190824),\n",
       " ('mr', 188900),\n",
       " ('feeling', 188644),\n",
       " ('actually', 188220),\n",
       " ('suddenly', 187313),\n",
       " ('anyone', 187245),\n",
       " ('seen', 186447),\n",
       " ('slowly', 186398),\n",
       " ('sighed', 184346),\n",
       " ('luna', 183894),\n",
       " ('spell', 183553),\n",
       " ('talk', 182824),\n",
       " ('making', 180959),\n",
       " ('shook', 179552),\n",
       " ('gone', 178634),\n",
       " ('light', 177510),\n",
       " ('rather', 177136),\n",
       " ('george', 177020),\n",
       " ('believe', 176735),\n",
       " ('second', 176435),\n",
       " ('blood', 176289),\n",
       " ('home', 175614),\n",
       " ('far', 175378),\n",
       " ('probably', 175349),\n",
       " ('held', 175034),\n",
       " ('granger', 173448),\n",
       " ('used', 173343),\n",
       " ('inside', 172833),\n",
       " ('opened', 171417),\n",
       " ('rest', 170746),\n",
       " ('taking', 170213),\n",
       " ('fred', 169566),\n",
       " ('half', 167888),\n",
       " ('muggle', 167888),\n",
       " ('stopped', 167220),\n",
       " ('hear', 167022),\n",
       " ('rose', 166667),\n",
       " ('idea', 166373),\n",
       " ('whispered', 166282),\n",
       " ('thank', 165984),\n",
       " ('coming', 164758),\n",
       " ('try', 164591),\n",
       " ('called', 164568),\n",
       " ('breath', 164378),\n",
       " ('care', 164329),\n",
       " ('across', 163994),\n",
       " ('slightly', 163288),\n",
       " ('tom', 163148),\n",
       " ('parents', 162405),\n",
       " ('yeah', 162074),\n",
       " ('students', 161343),\n",
       " ('needed', 161040),\n",
       " ('close', 160032),\n",
       " ('ask', 159987),\n",
       " ('laughed', 159593),\n",
       " ('may', 159088),\n",
       " ('slytherin', 158939),\n",
       " ('heart', 158902),\n",
       " ('watched', 158108),\n",
       " ('use', 157961),\n",
       " ('gryffindor', 157866),\n",
       " ('part', 157447),\n",
       " ('sitting', 156915),\n",
       " ('continued', 156904),\n",
       " ('morning', 156325),\n",
       " ('happy', 154648),\n",
       " ('feet', 154147),\n",
       " ('lot', 153864),\n",
       " ('red', 152758),\n",
       " ('pain', 152528),\n",
       " ('book', 150402),\n",
       " ('okay', 149465),\n",
       " ('remember', 149201),\n",
       " ('fact', 148719),\n",
       " ('hall', 148682),\n",
       " ('past', 148101),\n",
       " ('stared', 146469),\n",
       " ('reached', 146040),\n",
       " ('chapter', 145804),\n",
       " ('fine', 145801),\n",
       " ('along', 145702),\n",
       " ('however', 145443),\n",
       " ('ministry', 145354),\n",
       " ('thinking', 144814),\n",
       " ('wizard', 144046),\n",
       " ('wrong', 144040),\n",
       " ('onto', 143493),\n",
       " ('hope', 143027),\n",
       " ('alone', 142740),\n",
       " ('shoulder', 142477),\n",
       " ('read', 141693),\n",
       " ('set', 141629),\n",
       " ('bad', 140423),\n",
       " ('moved', 140051),\n",
       " ('standing', 139679),\n",
       " ('either', 139234),\n",
       " ('dead', 138573),\n",
       " ('chest', 138472),\n",
       " ('talking', 137429),\n",
       " ('fell', 137260),\n",
       " ('decided', 137247),\n",
       " ('minutes', 136055),\n",
       " ('potion', 136031),\n",
       " ('stay', 135863),\n",
       " ('ran', 135280),\n",
       " ('hurt', 134729),\n",
       " ('young', 134417),\n",
       " ('understand', 134273),\n",
       " ('mcgonagall', 134019),\n",
       " ('point', 133882),\n",
       " ('air', 133855),\n",
       " ('fingers', 133804),\n",
       " ('person', 133079),\n",
       " ('instead', 132965),\n",
       " ('kill', 132825),\n",
       " ('caught', 132816),\n",
       " ('matter', 132641),\n",
       " ('woman', 132271),\n",
       " ('potions', 132245),\n",
       " ('miss', 132187),\n",
       " ('days', 132130),\n",
       " ('others', 131070),\n",
       " ('ready', 130447),\n",
       " ('kiss', 130412),\n",
       " ('tonks', 130354),\n",
       " ('tears', 130240),\n",
       " ('ground', 130160),\n",
       " ('son', 129642),\n",
       " ('kept', 129227),\n",
       " ('taken', 128172),\n",
       " ('times', 128063),\n",
       " ('wait', 127776),\n",
       " ('full', 127736),\n",
       " ('deep', 127544),\n",
       " ('order', 127434),\n",
       " ('forward', 126988),\n",
       " ('curse', 126937),\n",
       " ('closed', 126766),\n",
       " ('eaters', 126091),\n",
       " ('noticed', 125396),\n",
       " ('story', 125127),\n",
       " ('magical', 124696),\n",
       " ('kind', 123685),\n",
       " ('lost', 123411),\n",
       " ('reason', 123372),\n",
       " ('raised', 123044),\n",
       " ('sleep', 122338),\n",
       " ('sound', 121845),\n",
       " ('thanks', 121228),\n",
       " ('move', 120528),\n",
       " ('blaise', 119960),\n",
       " ('eye', 119487),\n",
       " ('wall', 119083),\n",
       " ('different', 119067),\n",
       " ('whole', 119042),\n",
       " ('office', 117303),\n",
       " ('bellatrix', 117277),\n",
       " ('several', 116970),\n",
       " ('question', 116022),\n",
       " ('start', 115962),\n",
       " ('followed', 115446),\n",
       " ('word', 114961),\n",
       " ('turn', 114690),\n",
       " ('large', 114094),\n",
       " ('perhaps', 113696),\n",
       " ('anyway', 113625),\n",
       " ('class', 113580),\n",
       " ('answer', 113033),\n",
       " ('outside', 112944),\n",
       " ('holding', 112869),\n",
       " ('attention', 112384),\n",
       " ('hit', 112115),\n",
       " ('lupin', 111414),\n",
       " ('chair', 111398),\n",
       " ('answered', 111255),\n",
       " ('completely', 110957),\n",
       " ('cold', 110823),\n",
       " ('green', 110694),\n",
       " ('exactly', 110675),\n",
       " ('scorpius', 110516),\n",
       " ('quietly', 110265),\n",
       " ('waiting', 110251),\n",
       " ('four', 109428),\n",
       " ('immediately', 108626),\n",
       " ('mum', 108315),\n",
       " ('ago', 108168),\n",
       " ('minerva', 108027),\n",
       " ('robes', 107798),\n",
       " ('spoke', 107632),\n",
       " ('saying', 107626),\n",
       " ('longer', 107480),\n",
       " ('watching', 106933),\n",
       " ('today', 106907),\n",
       " ('leaving', 106728),\n",
       " ('stepped', 106291),\n",
       " ('true', 106153),\n",
       " ('child', 106088),\n",
       " ('seeing', 105600),\n",
       " ('hold', 105464),\n",
       " ('master', 105358),\n",
       " ('fire', 105307),\n",
       " ('pansy', 105043),\n",
       " ('staring', 104987),\n",
       " ('surprised', 104941),\n",
       " ('given', 104730),\n",
       " ('nearly', 104704),\n",
       " ('silence', 104538),\n",
       " ('witch', 104451),\n",
       " ('dad', 104352),\n",
       " ('turning', 103984),\n",
       " ('neck', 103934),\n",
       " ('nice', 103811),\n",
       " ('softly', 103689),\n",
       " ('headmaster', 103327),\n",
       " ('finished', 103176),\n",
       " ('meant', 102411),\n",
       " ('brought', 102043),\n",
       " ('closer', 102036),\n",
       " ('simply', 101834),\n",
       " ('war', 101008),\n",
       " ('grabbed', 100650),\n",
       " ('show', 100448),\n",
       " ('hell', 100387),\n",
       " ('top', 99986),\n",
       " ('bloody', 99647),\n",
       " ('grinned', 99617),\n",
       " ('call', 99603),\n",
       " ('charm', 99507),\n",
       " ('managed', 99364),\n",
       " ('realized', 99214),\n",
       " ('change', 99118),\n",
       " ('says', 98993),\n",
       " ('narcissa', 98939),\n",
       " ('looks', 98929),\n",
       " ('brother', 98833),\n",
       " ('quidditch', 98425),\n",
       " ('running', 98043),\n",
       " ('children', 97891),\n",
       " ('kissed', 97438),\n",
       " ('killed', 97325),\n",
       " ('chance', 97261),\n",
       " ('speak', 96922),\n",
       " ('common', 96782),\n",
       " ('shut', 96718),\n",
       " ('skin', 96715),\n",
       " ('mrs', 96430),\n",
       " ('week', 96179),\n",
       " ('sent', 95005),\n",
       " ('known', 94872),\n",
       " ('alright', 94214),\n",
       " ('white', 94075),\n",
       " ('added', 93861),\n",
       " ('pointed', 93783),\n",
       " ('run', 93751),\n",
       " ('castle', 93664),\n",
       " ('rolled', 93468),\n",
       " ('five', 93375),\n",
       " ('met', 93361),\n",
       " ('less', 93325),\n",
       " ('molly', 92834),\n",
       " ('expression', 92805),\n",
       " ('boys', 92763),\n",
       " ('supposed', 92605),\n",
       " ('walking', 92498),\n",
       " ('whatever', 92452),\n",
       " ('returned', 92442),\n",
       " ('knowing', 92264),\n",
       " ('fight', 92184),\n",
       " ('muttered', 92146),\n",
       " ('hours', 92087),\n",
       " ('cast', 91978),\n",
       " ('appeared', 91859),\n",
       " ('girls', 91619),\n",
       " ('leaned', 91520),\n",
       " ('giving', 91238),\n",
       " ('upon', 90746),\n",
       " ('happen', 90621),\n",
       " ('books', 90511),\n",
       " ('water', 90308),\n",
       " ('thoughts', 90117),\n",
       " ('pretty', 89937),\n",
       " ('shrugged', 89936),\n",
       " ('sort', 89724),\n",
       " ('spells', 89242),\n",
       " ('guess', 89208),\n",
       " ('throat', 89105),\n",
       " ('letter', 88886),\n",
       " ('gently', 88837),\n",
       " ('real', 88788),\n",
       " ('worry', 88535),\n",
       " ('big', 88349),\n",
       " ('pushed', 88075),\n",
       " ('loved', 88030),\n",
       " ('hagrid', 87461),\n",
       " ('stairs', 87414),\n",
       " ('possible', 87267),\n",
       " ('surprise', 87094),\n",
       " ('couple', 86862),\n",
       " ('glanced', 86713),\n",
       " ('meet', 86088),\n",
       " ('passed', 85884),\n",
       " ('seem', 85869),\n",
       " ('fear', 85572),\n",
       " ('bill', 85367),\n",
       " ('beside', 85145),\n",
       " ('watch', 84880),\n",
       " ('become', 84871),\n",
       " ('power', 84861),\n",
       " ('desk', 84732),\n",
       " ('sit', 84699),\n",
       " ('stand', 84692),\n",
       " ('placed', 84678),\n",
       " ('smiling', 84287),\n",
       " ('dinner', 84191),\n",
       " ('merlin', 83730),\n",
       " ('late', 83696),\n",
       " ('although', 83419),\n",
       " ('sense', 83389),\n",
       " ('safe', 83379),\n",
       " ('corner', 83264),\n",
       " ('toward', 83222),\n",
       " ('die', 82778),\n",
       " ('sir', 82413),\n",
       " ('wizards', 82240),\n",
       " ('stupid', 82099),\n",
       " ('bring', 81879),\n",
       " ('walk', 81856),\n",
       " ('eater', 81557),\n",
       " ('soft', 81437),\n",
       " ('baby', 81202),\n",
       " ('shot', 81076),\n",
       " ('anymore', 80722),\n",
       " ('break', 80593),\n",
       " ('kitchen', 80498),\n",
       " ('knows', 80396),\n",
       " ('snapped', 80365),\n",
       " ('agreed', 80117),\n",
       " ('wondered', 80064),\n",
       " ('short', 80036),\n",
       " ('near', 79656),\n",
       " ('wish', 79463),\n",
       " ('free', 79424),\n",
       " ('quiet', 79326),\n",
       " ('telling', 79311),\n",
       " ('blue', 79041),\n",
       " ('group', 78655),\n",
       " ('changed', 78602),\n",
       " ('window', 78561),\n",
       " ('sister', 78541),\n",
       " ('laugh', 78506),\n",
       " ('peter', 78438),\n",
       " ('moving', 78415),\n",
       " ('pulling', 78201),\n",
       " ('return', 78043),\n",
       " ('charlie', 78028),\n",
       " ('plan', 77886),\n",
       " ('angry', 77839),\n",
       " ('case', 77632),\n",
       " ('trust', 77182),\n",
       " ('explained', 77045),\n",
       " ('reading', 76938),\n",
       " ('dropped', 76829),\n",
       " ('shoulders', 76586),\n",
       " ('barely', 76486),\n",
       " ('sight', 76084),\n",
       " ('gaze', 75974),\n",
       " ('cut', 75736),\n",
       " ('live', 75692),\n",
       " ('beautiful', 75164),\n",
       " ('especially', 75124),\n",
       " ('died', 74943),\n",
       " ('figure', 74782),\n",
       " ('within', 74655),\n",
       " ('working', 74641),\n",
       " ('clear', 74634),\n",
       " ('christmas', 74621),\n",
       " ('shaking', 74471),\n",
       " ('legs', 74337),\n",
       " ('tonight', 74335),\n",
       " ('memory', 74324),\n",
       " ('worried', 74289),\n",
       " ('control', 74173),\n",
       " ('months', 74164),\n",
       " ('spent', 74126),\n",
       " ('seat', 74092),\n",
       " ('entire', 73873),\n",
       " ('shouted', 73871),\n",
       " ('dear', 73788),\n",
       " ('living', 73725),\n",
       " ('frowned', 73412),\n",
       " ('straight', 72997),\n",
       " ('fall', 72961),\n",
       " ('stomach', 72958),\n",
       " ('hour', 72908),\n",
       " ('conversation', 72717),\n",
       " ('stone', 72589),\n",
       " ('wizarding', 72049),\n",
       " ('allowed', 71913),\n",
       " ('form', 71904),\n",
       " ('fun', 71892),\n",
       " ('remembered', 71773),\n",
       " ('tone', 71757),\n",
       " ('afraid', 71664),\n",
       " ('filled', 71410),\n",
       " ('entered', 71349),\n",
       " ('picked', 71214),\n",
       " ('anger', 71067),\n",
       " ('glad', 70958),\n",
       " ('touch', 70842),\n",
       " ('broke', 70829),\n",
       " ('quick', 70826),\n",
       " ('step', 70643),\n",
       " ('silent', 70309),\n",
       " ('nose', 70224),\n",
       " ('truth', 70172),\n",
       " ('play', 70093),\n",
       " ('grin', 70038),\n",
       " ('meeting', 69811),\n",
       " ('cried', 69784),\n",
       " ('hey', 69595),\n",
       " ('laughing', 69564),\n",
       " ('auror', 69479),\n",
       " ('important', 69421),\n",
       " ('smirked', 69180),\n",
       " ('certain', 69093),\n",
       " ('warm', 68887),\n",
       " ('empty', 68840),\n",
       " ('none', 68768),\n",
       " ('became', 68593),\n",
       " ('team', 68504),\n",
       " ('weeks', 68462),\n",
       " ('high', 68190),\n",
       " ('using', 67988),\n",
       " ('food', 67988),\n",
       " ('percy', 67885),\n",
       " ('older', 67539),\n",
       " ('fleur', 67353),\n",
       " ('hate', 67233),\n",
       " ('expected', 67021),\n",
       " ('wide', 66946),\n",
       " ('threw', 66803),\n",
       " ('cheek', 66505),\n",
       " ('breakfast', 66301),\n",
       " ('yelled', 66294),\n",
       " ('worse', 66253),\n",
       " ('elf', 66177),\n",
       " ('problem', 66068),\n",
       " ('perfect', 65761),\n",
       " ('teddy', 65700),\n",
       " ('ones', 65636),\n",
       " ('cloak', 65609),\n",
       " ('clearly', 65588),\n",
       " ('n', 65580),\n",
       " ('memories', 65417),\n",
       " ('waited', 65172),\n",
       " ('shock', 64885),\n",
       " ('obviously', 64805),\n",
       " ('liked', 64736),\n",
       " ('ten', 64683),\n",
       " ('wife', 64628),\n",
       " ('alive', 64533),\n",
       " ('arrived', 64433),\n",
       " ('sometimes', 64423),\n",
       " ('riddle', 64406),\n",
       " ('certainly', 64339),\n",
       " ('note', 64220),\n",
       " ('carefully', 63946),\n",
       " ('summer', 63774),\n",
       " ('despite', 63538),\n",
       " ('glass', 63377),\n",
       " ('job', 63292),\n",
       " ('gotten', 63282),\n",
       " ('information', 63244),\n",
       " ('wrapped', 63233),\n",
       " ('daphne', 63219),\n",
       " ('loud', 63183),\n",
       " ('forced', 62993),\n",
       " ('madam', 62936),\n",
       " ('except', 62902),\n",
       " ('ear', 62874),\n",
       " ('strong', 62720),\n",
       " ('clothes', 62612),\n",
       " ('tomorrow', 62567),\n",
       " ('battle', 62477),\n",
       " ('library', 62467),\n",
       " ('tea', 62455),\n",
       " ('deal', 62414),\n",
       " ('strange', 62198),\n",
       " ('trouble', 62178),\n",
       " ('calm', 62173),\n",
       " ('worked', 61961),\n",
       " ('minute', 61823),\n",
       " ('confused', 61808),\n",
       " ('owl', 61770),\n",
       " ('middle', 61666),\n",
       " ('headed', 61392),\n",
       " ('easy', 61289),\n",
       " ('evening', 61278),\n",
       " ('normal', 61127),\n",
       " ('daughter', 61029),\n",
       " ('mine', 60988),\n",
       " ('shirt', 60680),\n",
       " ('parchment', 60642),\n",
       " ('lay', 60600),\n",
       " ('secret', 60585),\n",
       " ('seems', 60555),\n",
       " ('makes', 60477),\n",
       " ('twins', 60457),\n",
       " ('paused', 60414),\n",
       " ('apparently', 60413),\n",
       " ('notice', 60309),\n",
       " ('line', 60085),\n",
       " ('tired', 59950),\n",
       " ('suppose', 59728),\n",
       " ('moments', 59673),\n",
       " ('broom', 59654),\n",
       " ('somehow', 59182),\n",
       " ('led', 59114),\n",
       " ('tongue', 58955),\n",
       " ('broken', 58907),\n",
       " ('usual', 58743),\n",
       " ('lying', 58710),\n",
       " ('promise', 58686),\n",
       " ('cup', 58664),\n",
       " ('piece', 58560),\n",
       " ('pale', 58413),\n",
       " ('men', 58205),\n",
       " ('arthur', 58125),\n",
       " ('chuckled', 58087),\n",
       " ('familiar', 57891),\n",
       " ('sounded', 57848),\n",
       " ('questions', 57839),\n",
       " ('game', 57802),\n",
       " ('attack', 57784),\n",
       " ('doubt', 57764),\n",
       " ('mate', 57580),\n",
       " ('muggles', 57500),\n",
       " ('mad', 57492),\n",
       " ('save', 57480),\n",
       " ('wonder', 57458),\n",
       " ('means', 57455),\n",
       " ('finger', 57298),\n",
       " ('bright', 57247),\n",
       " ('helped', 57210),\n",
       " ('uncle', 57062),\n",
       " ('bella', 57011),\n",
       " ('explain', 56926),\n",
       " ('aurors', 56857),\n",
       " ('pressed', 56809),\n",
       " ('gasped', 56723),\n",
       " ('minister', 56705),\n",
       " ('third', 56688),\n",
       " ('jumped', 56631),\n",
       " ('charms', 56588),\n",
       " ('hissed', 56568),\n",
       " ('situation', 56493),\n",
       " ('hospital', 56298),\n",
       " ('whether', 56141),\n",
       " ('position', 56053),\n",
       " ('lifted', 56028),\n",
       " ('glared', 56005),\n",
       " ('manor', 55831),\n",
       " ('moody', 55733),\n",
       " ('covered', 55680),\n",
       " ('fast', 55600),\n",
       " ('catch', 55335),\n",
       " ('shall', 55248),\n",
       " ('seconds', 55219),\n",
       " ('wants', 55065),\n",
       " ('often', 54993),\n",
       " ('asleep', 54770),\n",
       " ('asking', 54634),\n",
       " ('early', 54633),\n",
       " ('dobby', 54364),\n",
       " ('teeth', 54356),\n",
       " ('pomfrey', 53989),\n",
       " ('listen', 53953),\n",
       " ('wearing', 53933),\n",
       " ('neither', 53751),\n",
       " ('al', 53654),\n",
       " ('bag', 53593),\n",
       " ('write', 53519),\n",
       " ('follow', 53423),\n",
       " ('kingsley', 53415),\n",
       " ('following', 53349),\n",
       " ('sigh', 53320),\n",
       " ('forget', 53302),\n",
       " ('letting', 53290),\n",
       " ('besides', 53278),\n",
       " ('screamed', 53229),\n",
       " ('soul', 53227),\n",
       " ('truly', 53173),\n",
       " ('pull', 53163),\n",
       " ('mark', 53150),\n",
       " ('student', 52990),\n",
       " ('ended', 52751),\n",
       " ('beginning', 52726),\n",
       " ('keeping', 52725),\n",
       " ('fighting', 52652),\n",
       " ('hoped', 52640),\n",
       " ('playing', 52526),\n",
       " ('flew', 52321),\n",
       " ('likely', 52264),\n",
       " ('silver', 52229),\n",
       " ('brown', 52216),\n",
       " ('wondering', 52161),\n",
       " ('eyebrow', 52122),\n",
       " ('husband', 52093),\n",
       " ('guys', 52075),\n",
       " ('easily', 52050),\n",
       " ('lip', 52048),\n",
       " ('direction', 52008),\n",
       " ('usually', 51999),\n",
       " ('hot', 51871),\n",
       " ('learn', 51857),\n",
       " ('hated', 51847),\n",
       " ('crying', 51792),\n",
       " ('future', 51768),\n",
       " ('ah', 51731),\n",
       " ('starting', 51697),\n",
       " ('edge', 51564),\n",
       " ('somewhere', 51552),\n",
       " ('eat', 51480),\n",
       " ('enjoy', 51475),\n",
       " ('flying', 51328),\n",
       " ('six', 51325),\n",
       " ('self', 51271),\n",
       " ('azkaban', 50967),\n",
       " ('low', 50893),\n",
       " ('shocked', 50754),\n",
       " ('offered', 50736),\n",
       " ('cheeks', 50577),\n",
       " ('cry', 50517),\n",
       " ('hoping', 50509),\n",
       " ('falling', 50478),\n",
       " ('damn', 50429),\n",
       " ('age', 50424),\n",
       " ('powerful', 50388),\n",
       " ('tightly', 50349),\n",
       " ('hide', 50281),\n",
       " ('serious', 50247),\n",
       " ('earlier', 50236),\n",
       " ('send', 50206),\n",
       " ('knees', 50147),\n",
       " ('money', 50007),\n",
       " ('train', 49983),\n",
       " ('drink', 49836),\n",
       " ('missed', 49826),\n",
       " ('pair', 49793),\n",
       " ('ravenclaw', 49786),\n",
       " ('pocket', 49758),\n",
       " ('disappeared', 49744),\n",
       " ('speaking', 49739),\n",
       " ('choice', 49686),\n",
       " ('god', 49580),\n",
       " ('lived', 49532),\n",
       " ('aware', 49515),\n",
       " ('single', 49469),\n",
       " ('spot', 49403),\n",
       " ('expect', 49216),\n",
       " ('definitely', 49178),\n",
       " ('wake', 49124),\n",
       " ('handed', 48944),\n",
       " ('putting', 48808),\n",
       " ('present', 48758),\n",
       " ('eventually', 48750),\n",
       " ('hug', 48749),\n",
       " ('aunt', 48652),\n",
       " ('bedroom', 48531),\n",
       " ('forest', 48464),\n",
       " ('mirror', 48428),\n",
       " ('killing', 48341),\n",
       " ('ears', 48292),\n",
       " ('dress', 48171),\n",
       " ('simple', 48102),\n",
       " ('scared', 47933),\n",
       " ('check', 47890),\n",
       " ('waved', 47791),\n",
       " ('laughter', 47776),\n",
       " ('paper', 47704),\n",
       " ('continue', 47581),\n",
       " ('admit', 47576),\n",
       " ('join', 47365),\n",
       " ('sounds', 47345),\n",
       " ('exclaimed', 47232),\n",
       " ('feelings', 47147),\n",
       " ('force', 47096),\n",
       " ('breathing', 47048),\n",
       " ('blinked', 46983),\n",
       " ('corridor', 46976),\n",
       " ('box', 46921),\n",
       " ('slipped', 46775),\n",
       " ('relief', 46715),\n",
       " ('showed', 46700),\n",
       " ('forehead', 46574),\n",
       " ('sleeping', 46554),\n",
       " ('writing', 46547),\n",
       " ('smirk', 46477),\n",
       " ('doors', 46438),\n",
       " ('younger', 46387),\n",
       " ('final', 46301),\n",
       " ('news', 46246),\n",
       " ('wands', 46225),\n",
       " ('cannot', 46119),\n",
       " ('murmured', 46093),\n",
       " ('protect', 45957),\n",
       " ('causing', 45865),\n",
       " ('ok', 45809),\n",
       " ('ball', 45734),\n",
       " ('bathroom', 45654),\n",
       " ('indeed', 45634),\n",
       " ('snake', 45455),\n",
       " ('kissing', 45430),\n",
       " ('twenty', 45411),\n",
       " ('wards', 45191),\n",
       " ('dangerous', 45148),\n",
       " ('steps', 45138),\n",
       " ('business', 45114),\n",
       " ('seamus', 45063),\n",
       " ('lunch', 44976),\n",
       " ('dean', 44921),\n",
       " ('glance', 44833),\n",
       " ('evil', 44804),\n",
       " ('obvious', 44691),\n",
       " ('alley', 44691),\n",
       " ('cause', 44595),\n",
       " ('entrance', 44577),\n",
       " ('dream', 44574),\n",
       " ('sudden', 44492),\n",
       " ('party', 44492),\n",
       " ('stayed', 44429),\n",
       " ('ring', 44422),\n",
       " ('cedric', 44401),\n",
       " ('married', 44395),\n",
       " ('busy', 44393),\n",
       " ('foot', 44386),\n",
       " ('apart', 44378),\n",
       " ('dragon', 44354),\n",
       " ('visit', 44243),\n",
       " ('touched', 44215),\n",
       " ('fuck', 44205),\n",
       " ('honestly', 44169),\n",
       " ('difficult', 44167),\n",
       " ('needs', 44163),\n",
       " ('fault', 43996),\n",
       " ('imagine', 43992),\n",
       " ('drew', 43951),\n",
       " ('number', 43950),\n",
       " ('blonde', 43917),\n",
       " ('stuff', 43868),\n",
       " ('burst', 43738),\n",
       " ('leaning', 43700),\n",
       " ('walls', 43693),\n",
       " ('aside', 43677),\n",
       " ('human', 43638),\n",
       " ('groaned', 43617),\n",
       " ('slytherins', 43603),\n",
       " ('crowd', 43585),\n",
       " ('darkness', 43544),\n",
       " ('interrupted', 43353),\n",
       " ('hello', 43204),\n",
       " ('couch', 43193),\n",
       " ('silently', 43163),\n",
       " ('odd', 43156),\n",
       " ('teacher', 43108),\n",
       " ('learned', 43099),\n",
       " ('remained', 43079),\n",
       " ('tower', 43069),\n",
       " ('stated', 42866),\n",
       " ('werewolf', 42864),\n",
       " ('match', 42863),\n",
       " ('stuck', 42854),\n",
       " ('ahead', 42720),\n",
       " ('lavender', 42715),\n",
       " ('date', 42646),\n",
       " ('tight', 42581),\n",
       " ('growled', 42577),\n",
       " ('wanting', 42504),\n",
       " ('spend', 42476),\n",
       " ('allow', 42298),\n",
       " ('born', 42257),\n",
       " ('lose', 42233),\n",
       " ('points', 42097),\n",
       " ('finish', 42034),\n",
       " ('relationship', 42010),\n",
       " ('grew', 41992),\n",
       " ('act', 41951),\n",
       " ('heavy', 41948),\n",
       " ('hiding', 41928),\n",
       " ('realised', 41922),\n",
       " ('regulus', 41778),\n",
       " ('umbridge', 41764),\n",
       " ('response', 41752),\n",
       " ('shop', 41733),\n",
       " ('crossed', 41707)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем, что если в тексте попадается Harry Potter, то вносим его только в имя + фамилия. Если встречаем professor Snape, то учитываем только в частоте профессоров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 152kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from spacy)\n",
      "Collecting srsly<1.1.0,>=0.1.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/96/3350d3fa0cfa2b2ff341113d60b5bfe0ab8dd0e6b6b2c8b12157b4eb3000/srsly-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (185kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 8.8MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.5.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/19/f95c75562d18eb27219df3a3590b911e78d131b68466ad79fdf5847eaac4/blis-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.7MB 461kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting plac<1.2.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/b5/3e1714ebda8fd7c5859f9b216e381adc0a38b962f071568fd00d67e1b1ca/cymem-2.0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/6b/e07fad36913879757c90ba03d6fb7f406f7279e11dcefc105ee562de63ea/preshed-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (119kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 13.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from spacy)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 14.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/e6/63f160a4fdf0e875d16b28f972083606d8d54f56cd30cb8929f9a1ee700e/murmurhash-1.0.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting thinc<7.4.0,>=7.3.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 757kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl (156kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 9.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<4,>=3.0.2 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 11.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/74/6e4f91745020f967d09332bb2b8b9b10090957334692eb88ea4afe91b77f/urllib3-1.25.8-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 11.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/e3/afebe61c546d18fb1709a61bee788254b40e736cff7271c7de5de2dc4128/idna-2.9-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 13.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Requirement already satisfied: more-itertools in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Installing collected packages: srsly, blis, plac, cymem, catalogue, wasabi, murmurhash, preshed, certifi, chardet, urllib3, idna, requests, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 certifi-2019.11.28 chardet-3.0.4 cymem-2.0.3 idna-2.9 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 requests-2.23.0 spacy-2.2.3 srsly-1.0.1 thinc-7.3.1 urllib3-1.25.8 wasabi-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1156/36225 [00:40<08:42, 67.12it/s]"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NER = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ners(text, ner, names, full_names, prof_names, path=None):\n",
    "    def inc(d, key):\n",
    "        if key in d:\n",
    "            d[key] += 1\n",
    "        else:\n",
    "            d[key] = 1\n",
    "    \n",
    "    ners = ner(text)\n",
    "\n",
    "    for entity in ners.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            name = entity.text\n",
    "            if entity.start != 0:\n",
    "                prev_token = ners[entity.start - 1]\n",
    "                if prev_token.text.lower() == 'professor':\n",
    "                    inc(prof_names, name)\n",
    "                    if name.lower() == 'longbottom':\n",
    "                        print(path, prev_token, name)\n",
    "                    continue\n",
    "            if len(name.split()) >= 2:\n",
    "                inc(full_names, name)\n",
    "            else:\n",
    "                inc(names, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be4a10a9d3a4f39be388cb0084a13ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6687343 Professor Longbottom\n",
      "9110929 Professor Longbottom\n",
      "9110929 Professor Longbottom\n",
      "9110929 Professor Longbottom\n",
      "11255901 Professor Longbottom\n"
     ]
    }
   ],
   "source": [
    "def process_file(args):\n",
    "    names, full_names, prof_names, path = args\n",
    "    full_path = os.path.join(RAW_TEXTS_DIR, path)\n",
    "    with open(full_path, 'r') as f:\n",
    "        text = f.read()\n",
    "        step = min(MAX_NER, len(text))\n",
    "        for i in range(0, len(text) - step + 1, step):\n",
    "            get_ners(text[i: i + step], ner, names, full_names, prof_names, path)\n",
    "\n",
    "\n",
    "names = dict()\n",
    "full_names = dict()\n",
    "prof_names = dict()\n",
    "\n",
    "ner = spacy.load('en')\n",
    "\n",
    "with multiprocessing.Manager() as manager:\n",
    "    shared_names = manager.dict()\n",
    "    shared_full_names = manager.dict()\n",
    "    shared_prof_names = manager.dict()\n",
    "    with multiprocessing.Pool(processes=56) as pool:\n",
    "        files = os.listdir(RAW_TEXTS_DIR)\n",
    "        for _ in tqdm(pool.imap_unordered(\n",
    "            process_file, \n",
    "            [(shared_names, shared_full_names, shared_prof_names, file) for file in files]\n",
    "        )):\n",
    "            pass\n",
    "    names = dict(shared_names)\n",
    "    full_names = dict(shared_full_names)\n",
    "    prof_names = dict(shared_prof_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = sorted(names.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_full_names = sorted(full_names.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_prof_names = sorted(prof_names.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('top_10_names.pickle', 'wb') as f:\n",
    "#     pickle.dump([top_names, top_full_names, top_prof_names], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Harry', 1092227), ('Ron', 551810), ('Ginny', 385226), ('James', 327416), ('Lily', 286434), ('Dumbledore', 195533), ('Remus', 184537), ('Severus', 178023), ('Hermione', 169756), ('Sirius', 168815)]\n",
      "[('Harry Potter', 96440), ('Hermione Granger', 25153), ('Draco Malfoy', 20311), ('Lucius Malfoy', 19595), ('James Potter', 18760), ('Albus Dumbledore', 17158), ('Miss Granger', 15163), ('Sirius Black', 14995), ('Tom Riddle', 14342), ('Remus Lupin', 11626)]\n",
      "[('Snape', 38331), ('McGonagall', 37876), ('Dumbledore', 21226), ('Lupin', 9414), ('Flitwick', 8582), ('Slughorn', 5434), ('Sprout', 5256), ('Umbridge', 2353), ('Trelawney', 2225), ('Longbottom', 2221)]\n"
     ]
    }
   ],
   "source": [
    "with open('top_10_names.pickle', 'rb') as f:\n",
    "    top_names, top_full_names, top_prof_names = pickle.load(f)\n",
    "print(top_names)\n",
    "print(top_full_names)\n",
    "print(top_prof_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "## Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ulyanin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fastText'...\n",
      "remote: Enumerating objects: 22, done.\u001b[K\n",
      "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 3679 (delta 2), reused 17 (delta 1), pack-reused 3657\u001b[K\n",
      "Receiving objects: 100% (3679/3679), 8.10 MiB | 6.36 MiB/s, done.\n",
      "Resolving deltas: 100% (2313/2313), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./fastText\n",
      "Requirement already satisfied: numpy in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from fasttext==0.9.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from fasttext==0.9.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages (from fasttext==0.9.1)\n",
      "Installing collected packages: fasttext\n",
      "  Running setup.py install for fasttext ... \u001b[?25l-"
     ]
    }
   ],
   "source": [
    "! pip3 install fastText/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pymorphy2\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_FILE_NAME = 'fanfiction_texts_processed.txt'\n",
    "PROCESSED_FILE_NAME_LEMMATIZED = 'fanfiction_texts_lemmatized.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ulyanin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {\n",
    "        'CC':None, # coordin. conjunction (and, but, or)  \n",
    "        'CD':wn.NOUN, # cardinal number (one, two)             \n",
    "        'DT':None, # determiner (a, the)                    \n",
    "        'EX':wn.ADV, # existential ‘there’ (there)           \n",
    "        'FW':None, # foreign word (mea culpa)             \n",
    "        'IN':wn.ADV, # preposition/sub-conj (of, in, by)   \n",
    "#         'JJ':[wn.ADJ, wn.ADJ_SAT], # adjective (yellow)                  \n",
    "#         'JJR':[wn.ADJ, wn.ADJ_SAT], # adj., comparative (bigger)          \n",
    "#         'JJS':[wn.ADJ, wn.ADJ_SAT], # adj., superlative (wildest)           \n",
    "        'LS':None, # list item marker (1, 2, One)          \n",
    "        'MD':None, # modal (can, should)                    \n",
    "        'NN':wn.NOUN, # noun, sing. or mass (llama)          \n",
    "        'NNS':wn.NOUN, # noun, plural (llamas)                  \n",
    "        'NNP':wn.NOUN, # proper noun, sing. (IBM)              \n",
    "        'NNPS':wn.NOUN, # proper noun, plural (Carolinas)\n",
    "#         'PDT':[wn.ADJ, wn.ADJ_SAT], # predeterminer (all, both)            \n",
    "        'POS':None, # possessive ending (’s )               \n",
    "        'PRP':None, # personal pronoun (I, you, he)     \n",
    "        'PRP$':None, # possessive pronoun (your, one’s)    \n",
    "        'RB':wn.ADV, # adverb (quickly, never)            \n",
    "        'RBR':wn.ADV, # adverb, comparative (faster)        \n",
    "        'RBS':wn.ADV, # adverb, superlative (fastest)     \n",
    "#         'RP':[wn.ADJ, wn.ADJ_SAT], # particle (up, off)\n",
    "        'SYM':None, # symbol (+,%, &)\n",
    "        'TO':None, # “to” (to)\n",
    "        'UH':None, # interjection (ah, oops)\n",
    "        'VB':wn.VERB, # verb base form (eat)\n",
    "        'VBD':wn.VERB, # verb past tense (ate)\n",
    "        'VBG':wn.VERB, # verb gerund (eating)\n",
    "        'VBN':wn.VERB, # verb past participle (eaten)\n",
    "        'VBP':wn.VERB, # verb non-3sg pres (eat)\n",
    "        'VBZ':wn.VERB, # verb 3sg pres (eats)\n",
    "        'WDT':None, # wh-determiner (which, that)\n",
    "        'WP':None, # wh-pronoun (what, who)\n",
    "        'WP$':None, # possessive (wh- whose)\n",
    "        'WRB':None, # wh-adverb (how, where)\n",
    "        '$':None, #  dollar sign ($)\n",
    "        '#':None, # pound sign (#)\n",
    "        '“':None, # left quote (‘ or “)\n",
    "        '”':None, # right quote (’ or ”)\n",
    "        '(':None, # left parenthesis ([, (, {, <)\n",
    "        ')':None, # right parenthesis (], ), }, >)\n",
    "        ',':None, # comma (,)\n",
    "        '.':None, # sentence-final punc (. ! ?)\n",
    "        ':':None # mid-sentence punc (: ; ... – -)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    return tag_map.get(tag, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "  \n",
    "# print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "# print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_word(word):\n",
    "    pos_tag = get_wordnet_pos(word)\n",
    "    if pos_tag:\n",
    "        wn = lemmatizer.lemmatize(word, pos_tag)\n",
    "        return wn\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(sentence):\n",
    "    return ' '.join([lemmatize_word(word) for word in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(words):\n",
    "    return [lemmatize_word(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "punkt_p = re.compile(\"([\\.\\\\!?,'/\\(\\)\\\"-—…:–;«»_])\")\n",
    "punkt_sub = r\" \\1 \"\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    processed_sentence = punkt_p.sub(punkt_sub, sentence).lower()\n",
    "    words = processed_sentence.split()\n",
    "    return ' '.join(process_words[words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return lemmatize(words_only(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_with_tokenizer_and_lemmatizer(pool, punkt_p, punkt_sub, tokenizer, full_path, out_f):\n",
    "#     pymorphy=pymorphy2.MorphAnalyzer(lang='uk')\n",
    "    with open(full_path, 'r') as in_f:\n",
    "        text = in_f.read() \n",
    "        sentences = tokenizer.tokenize(text.strip())\n",
    "        processed = []\n",
    "        for sentence in sentences:\n",
    "            processed_sentence = punkt_p.sub(punkt_sub, sentence).lower()\n",
    "            processed_sentence = lemmatize_sentence(processed_sentence)\n",
    "            processed.append(processed_sentence)\n",
    "        print('\\n'.join(processed), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_with_tokenizer_and_lemmatizer_parallel(pool, punkt_p, punkt_sub, tokenizer, full_path, out_f):\n",
    "#     pymorphy=pymorphy2.MorphAnalyzer(lang='uk')\n",
    "    with open(full_path, 'r') as in_f:\n",
    "        text = in_f.read() \n",
    "        sentences = tokenizer.tokenize(text.strip())\n",
    "        processed = list(pool.imap(process_sentence, sentences))\n",
    "        print('\\n'.join(processed), file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(punkt_p, punkt_sub, tokenizer, full_path, out_f):\n",
    "    with open(full_path, 'r') as in_f:\n",
    "        text = in_f.read() \n",
    "        processed = punkt_p.sub(punkt_sub, text).lower()\n",
    "        print(processed, file=out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(process_func, out_file_name):\n",
    "    # from the https://github.com/facebookresearch/fastText/blob/master/docs/supervised-tutorial.md\n",
    "    punkt_p = re.compile(\"([\\.\\\\!?,'/\\(\\)\\\"-—…–:;«»_])\")\n",
    "    punkt_sub = r\" \\1 \"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    with multiprocessing.Pool(56) as pool:\n",
    "        with open(out_file_name, 'w') as out_f:\n",
    "            for path in tqdm(os.listdir(RAW_TEXTS_DIR)):\n",
    "                full_path = os.path.join(RAW_TEXTS_DIR, path)\n",
    "                process_func(pool, punkt_p, punkt_sub, tokenizer, full_path, out_f)\n",
    "#             print(proc_text, file=out_f)          \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a388a30c884d3795ffd1bfd793fb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "process_files(process_file_with_tokenizer_and_lemmatizer_parallel, PROCESSED_FILE_NAME_LEMMATIZED)\n",
    "# process_files(process_file_with_tokenizer_and_lemmatizer, PROCESSED_FILE_NAME_LEMMATIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3d 5h 8min 8s, sys: 30.8 s, total: 3d 5h 8min 39s\n",
      "Wall time: 1h 23min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_model = fasttext.train_unsupervised(\n",
    "    PROCESSED_FILE_NAME_LEMMATIZED, \n",
    "    minn=3,\n",
    "    maxn=4, \n",
    "    dim=256,\n",
    "    verbose=3, \n",
    "    loss='hs', \n",
    "    thread=56\n",
    ")\n",
    "ft_model.save_model(\"ft_model_lemmatized3.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model.save_model(\"ft_model_lemmatized3.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft_model = fasttext.load_model(\"ft_model_lemmatized3.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7412028312683105, 'muggleborns'),\n",
       " (0.7222573161125183, 'magicals'),\n",
       " (0.7133464217185974, 'mundanes'),\n",
       " (0.6878073811531067, 'mugglest'),\n",
       " (0.678754448890686, 'muggle'),\n",
       " (0.656581699848175, 'mugglborns'),\n",
       " (0.6540908813476562, 'muggling'),\n",
       " (0.6534696221351624, 'mugglebornes'),\n",
       " (0.6492902636528015, 'halfbloods'),\n",
       " (0.6440216302871704, 'muggleborne')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('muggles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Синонимы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ближайшие соседи -- не всегда синонимы, поэтому к muggles нашлись также и magicals, но также в ближайших соседях есть и halfbloods, и разные формы и модификации слова muggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7412028312683105, 'muggleborns'),\n",
       " (0.7222573161125183, 'magicals'),\n",
       " (0.7133464217185974, 'mundanes'),\n",
       " (0.6878073811531067, 'mugglest'),\n",
       " (0.678754448890686, 'muggle'),\n",
       " (0.656581699848175, 'mugglborns'),\n",
       " (0.6540908813476562, 'muggling'),\n",
       " (0.6534696221351624, 'mugglebornes'),\n",
       " (0.6492902636528015, 'halfbloods'),\n",
       " (0.6440216302871704, 'muggleborne')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('muggles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К слову slytherin нашлись формы слова slytherin и другие факультеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8423709869384766, 'slythering'),\n",
       " (0.8331595063209534, 'slytherine'),\n",
       " (0.8124224543571472, 'slytherian'),\n",
       " (0.800957977771759, 'gryffindor'),\n",
       " (0.7870920300483704, 'slytherines'),\n",
       " (0.7834945917129517, 'slythindor'),\n",
       " (0.7755442261695862, 'slytheri'),\n",
       " (0.7707590460777283, 'ravenclaw'),\n",
       " (0.7696508169174194, 'hufflepuff'),\n",
       " (0.7675960063934326, 'griffindor')]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('slytherin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ассоциации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидали: harry - ginny, ron - hermione\n",
    "\n",
    "Hermione тоже есть в списке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6393308043479919, 'draco'),\n",
       " (0.636576771736145, 'he'),\n",
       " (0.562760055065155, 'severus'),\n",
       " (0.5604028701782227, 'hermione'),\n",
       " (0.5566599369049072, 'sirius'),\n",
       " (0.5448219180107117, 'snape'),\n",
       " (0.5431147813796997, 'harish'),\n",
       " (0.530278742313385, 'haiden'),\n",
       " (0.5154778957366943, 'remus'),\n",
       " (0.4945445954799652, ',')]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_analogies(\"harry\", \"ginny\", \"ron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидали: cedric - hufflepuff, slytherin -- кто-то из слизерина\n",
    "\n",
    "Получили модификации имени Седрик, но также и имена или фамилии учеников/выпускников факультета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.631982684135437, 'edric'),\n",
       " (0.5569972991943359, 'daedric'),\n",
       " (0.5018346905708313, 'fredric'),\n",
       " (0.49387407302856445, 'redrick'),\n",
       " (0.4759611487388611, 'hedrick'),\n",
       " (0.45686548948287964, 'malfoy'),\n",
       " (0.45332279801368713, 'friedrich'),\n",
       " (0.4425186216831207, 'severus'),\n",
       " (0.43910935521125793, 'lucius'),\n",
       " (0.4377565383911133, 'snape')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_analogies(\"сedric\", \"hufflepuff\", \"slytherin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидали: man - woman, mistress - master\n",
    "\n",
    "Есть в списке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7906824350357056, 'master'),\n",
       " (0.6452687978744507, 'kreacher'),\n",
       " (0.6271020770072937, 'dobby'),\n",
       " (0.6192078590393066, 'kreach'),\n",
       " (0.6053434014320374, 'tibby'),\n",
       " (0.5918794274330139, 'mipsy'),\n",
       " (0.58355313539505, 'pippy'),\n",
       " (0.5817848443984985, 'winky'),\n",
       " (0.5796759724617004, 'dibby'),\n",
       " (0.577107846736908, 'missy')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_analogies(\"man\", \"woman\", \"mistress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лишние слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрели, как работает функция doesnt_match в gensim, написали аналогичную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@returns The word further away from the mean of all word\n",
    "https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.doesnt_match\n",
    "\"\"\" \n",
    "def doesnt_match(model, words):\n",
    "    embeds = np.array([model[word] for word in words])\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        embeds[i] = embeds[i] / np.linalg.norm(embeds[i])\n",
    "        \n",
    "    mean = np.mean(embeds, axis=0)\n",
    "    dists = np.dot(embeds, mean)\n",
    "    return sorted(zip(dists, words))[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры со специфичными для книги словами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teapot'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doesnt_match(ft_model, [\"draco\", \"potter\", \"teapot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doesnt_match(ft_model, [\"draco\", \"potter\", \"wizard\", \"human\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doesnt_match(ft_model, [\"firebolt\", \"broom\", 'nimbus', \"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример с обычными словами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tv'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doesnt_match(ft_model, [\"teapot\", \"plate\", \"spoon\", \"tv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tsne(model, top_words):\n",
    "    top_words_processed = process_words(top_words)\n",
    "    top_words_vec = [model[word] for word in top_words_processed]\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42, n_jobs=1)\n",
    "    top_words_tsne = tsne.fit_transform(top_words_vec)\n",
    "    return top_words_tsne\n",
    "    \n",
    "    \n",
    "def plot_tsne(top_words_tsne, top_words):\n",
    "    p = figure(\n",
    "        tools=\"pan,wheel_zoom,reset,save\",\n",
    "        toolbar_location=\"above\",\n",
    "        title=\"fasttext T-SNE (top 1000 words)\"\n",
    "    )\n",
    "\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x1=top_words_tsne[:,0],\n",
    "            x2=top_words_tsne[:,1],\n",
    "            names=top_words\n",
    "        )\n",
    "    )\n",
    "\n",
    "    p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "    labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                      text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                      source=source, text_align='center')\n",
    "    p.add_layout(labels)\n",
    "    show(p)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 12s, sys: 0 ns, total: 6min 12s\n",
      "Wall time: 6.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_words_list = list(list(zip(*top_words))[0])\n",
    "top_words_tsne = fit_tsne(ft_model, top_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"e429f415-0213-434a-9ae9-c28672d77ff7\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"94e78dac-6b4b-425b-87c8-a83895eb773d\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"LinearAxis\"}],\"center\":[{\"id\":\"1017\",\"type\":\"Grid\"},{\"id\":\"1022\",\"type\":\"Grid\"},{\"id\":\"1038\",\"type\":\"LabelSet\"}],\"left\":[{\"id\":\"1018\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"1036\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1003\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1027\",\"type\":\"Toolbar\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"names\"},\"text_align\":\"center\",\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1038\",\"type\":\"LabelSet\"},{\"attributes\":{\"dimension\":1,\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1022\",\"type\":\"Grid\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"formatter\":{\"id\":\"1044\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1019\",\"type\":\"BasicTicker\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"Selection\"},{\"attributes\":{\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"callback\":null,\"data\":{\"names\":[\"harry\",\"said\",\"hermione\",\"would\",\"back\",\"one\",\"draco\",\"could\",\"like\",\"know\",\"eyes\",\"time\",\"ron\",\"looked\",\"get\",\"asked\",\"well\",\"even\",\"around\",\"see\",\"head\",\"going\",\"think\",\"still\",\"go\",\"face\",\"way\",\"severus\",\"room\",\"hand\",\"ginny\",\"sirius\",\"something\",\"want\",\"potter\",\"thought\",\"right\",\"snape\",\"away\",\"much\",\"two\",\"look\",\"never\",\"really\",\"knew\",\"first\",\"made\",\"let\",\"good\",\"malfoy\",\"wand\",\"little\",\"felt\",\"dumbledore\",\"turned\",\"james\",\"come\",\"got\",\"make\",\"took\",\"remus\",\"lily\",\"though\",\"sure\",\"looking\",\"say\",\"door\",\"tell\",\"dark\",\"take\",\"us\",\"long\",\"voice\",\"voldemort\",\"last\",\"told\",\"need\",\"left\",\"yes\",\"man\",\"wanted\",\"anything\",\"next\",\"oh\",\"came\",\"love\",\"nodded\",\"moment\",\"people\",\"year\",\"saw\",\"another\",\"things\",\"went\",\"hands\",\"death\",\"help\",\"day\",\"enough\",\"boy\",\"smiled\",\"professor\",\"mind\",\"nothing\",\"ever\",\"found\",\"hair\",\"always\",\"house\",\"find\",\"bit\",\"seemed\",\"behind\",\"hogwarts\",\"thing\",\"bed\",\"trying\",\"feel\",\"put\",\"started\",\"life\",\"since\",\"black\",\"night\",\"heard\",\"years\",\"smile\",\"without\",\"side\",\"better\",\"magic\",\"gave\",\"might\",\"weasley\",\"everyone\",\"father\",\"sat\",\"began\",\"someone\",\"almost\",\"walked\",\"done\",\"finally\",\"already\",\"three\",\"tried\",\"place\",\"every\",\"stood\",\"friends\",\"everything\",\"lord\",\"front\",\"small\",\"pulled\",\"also\",\"quickly\",\"course\",\"body\",\"girl\",\"keep\",\"best\",\"towards\",\"old\",\"else\",\"arms\",\"neville\",\"table\",\"mean\",\"give\",\"work\",\"family\",\"sorry\",\"albus\",\"end\",\"please\",\"great\",\"many\",\"world\",\"mother\",\"school\",\"lucius\",\"together\",\"new\",\"stop\",\"quite\",\"happened\",\"open\",\"leave\",\"maybe\",\"replied\",\"mouth\",\"soon\",\"must\",\"yet\",\"floor\",\"later\",\"getting\",\"able\",\"words\",\"name\",\"arm\",\"hard\",\"friend\",\"lips\",\"least\",\"mr\",\"feeling\",\"actually\",\"suddenly\",\"anyone\",\"seen\",\"slowly\",\"sighed\",\"luna\",\"spell\",\"talk\",\"making\",\"shook\",\"gone\",\"light\",\"rather\",\"george\",\"believe\",\"second\",\"blood\",\"home\",\"far\",\"probably\",\"held\",\"granger\",\"used\",\"inside\",\"opened\",\"rest\",\"taking\",\"fred\",\"half\",\"muggle\",\"stopped\",\"hear\",\"rose\",\"idea\",\"whispered\",\"thank\",\"coming\",\"try\",\"called\",\"breath\",\"care\",\"across\",\"slightly\",\"tom\",\"parents\",\"yeah\",\"students\",\"needed\",\"close\",\"ask\",\"laughed\",\"may\",\"slytherin\",\"heart\",\"watched\",\"use\",\"gryffindor\",\"part\",\"sitting\",\"continued\",\"morning\",\"happy\",\"feet\",\"lot\",\"red\",\"pain\",\"book\",\"okay\",\"remember\",\"fact\",\"hall\",\"past\",\"stared\",\"reached\",\"chapter\",\"fine\",\"along\",\"however\",\"ministry\",\"thinking\",\"wizard\",\"wrong\",\"onto\",\"hope\",\"alone\",\"shoulder\",\"read\",\"set\",\"bad\",\"moved\",\"standing\",\"either\",\"dead\",\"chest\",\"talking\",\"fell\",\"decided\",\"minutes\",\"potion\",\"stay\",\"ran\",\"hurt\",\"young\",\"understand\",\"mcgonagall\",\"point\",\"air\",\"fingers\",\"person\",\"instead\",\"kill\",\"caught\",\"matter\",\"woman\",\"potions\",\"miss\",\"days\",\"others\",\"ready\",\"kiss\",\"tonks\",\"tears\",\"ground\",\"son\",\"kept\",\"taken\",\"times\",\"wait\",\"full\",\"deep\",\"order\",\"forward\",\"curse\",\"closed\",\"eaters\",\"noticed\",\"story\",\"magical\",\"kind\",\"lost\",\"reason\",\"raised\",\"sleep\",\"sound\",\"thanks\",\"move\",\"blaise\",\"eye\",\"wall\",\"different\",\"whole\",\"office\",\"bellatrix\",\"several\",\"question\",\"start\",\"followed\",\"word\",\"turn\",\"large\",\"perhaps\",\"anyway\",\"class\",\"answer\",\"outside\",\"holding\",\"attention\",\"hit\",\"lupin\",\"chair\",\"answered\",\"completely\",\"cold\",\"green\",\"exactly\",\"scorpius\",\"quietly\",\"waiting\",\"four\",\"immediately\",\"mum\",\"ago\",\"minerva\",\"robes\",\"spoke\",\"saying\",\"longer\",\"watching\",\"today\",\"leaving\",\"stepped\",\"true\",\"child\",\"seeing\",\"hold\",\"master\",\"fire\",\"pansy\",\"staring\",\"surprised\",\"given\",\"nearly\",\"silence\",\"witch\",\"dad\",\"turning\",\"neck\",\"nice\",\"softly\",\"headmaster\",\"finished\",\"meant\",\"brought\",\"closer\",\"simply\",\"war\",\"grabbed\",\"show\",\"hell\",\"top\",\"bloody\",\"grinned\",\"call\",\"charm\",\"managed\",\"realized\",\"change\",\"says\",\"narcissa\",\"looks\",\"brother\",\"quidditch\",\"running\",\"children\",\"kissed\",\"killed\",\"chance\",\"speak\",\"common\",\"shut\",\"skin\",\"mrs\",\"week\",\"sent\",\"known\",\"alright\",\"white\",\"added\",\"pointed\",\"run\",\"castle\",\"rolled\",\"five\",\"met\",\"less\",\"molly\",\"expression\",\"boys\",\"supposed\",\"walking\",\"whatever\",\"returned\",\"knowing\",\"fight\",\"muttered\",\"hours\",\"cast\",\"appeared\",\"girls\",\"leaned\",\"giving\",\"upon\",\"happen\",\"books\",\"water\",\"thoughts\",\"pretty\",\"shrugged\",\"sort\",\"spells\",\"guess\",\"throat\",\"letter\",\"gently\",\"real\",\"worry\",\"big\",\"pushed\",\"loved\",\"hagrid\",\"stairs\",\"possible\",\"surprise\",\"couple\",\"glanced\",\"meet\",\"passed\",\"seem\",\"fear\",\"bill\",\"beside\",\"watch\",\"become\",\"power\",\"desk\",\"sit\",\"stand\",\"placed\",\"smiling\",\"dinner\",\"merlin\",\"late\",\"although\",\"sense\",\"safe\",\"corner\",\"toward\",\"die\",\"sir\",\"wizards\",\"stupid\",\"bring\",\"walk\",\"eater\",\"soft\",\"baby\",\"shot\",\"anymore\",\"break\",\"kitchen\",\"knows\",\"snapped\",\"agreed\",\"wondered\",\"short\",\"near\",\"wish\",\"free\",\"quiet\",\"telling\",\"blue\",\"group\",\"changed\",\"window\",\"sister\",\"laugh\",\"peter\",\"moving\",\"pulling\",\"return\",\"charlie\",\"plan\",\"angry\",\"case\",\"trust\",\"explained\",\"reading\",\"dropped\",\"shoulders\",\"barely\",\"sight\",\"gaze\",\"cut\",\"live\",\"beautiful\",\"especially\",\"died\",\"figure\",\"within\",\"working\",\"clear\",\"christmas\",\"shaking\",\"legs\",\"tonight\",\"memory\",\"worried\",\"control\",\"months\",\"spent\",\"seat\",\"entire\",\"shouted\",\"dear\",\"living\",\"frowned\",\"straight\",\"fall\",\"stomach\",\"hour\",\"conversation\",\"stone\",\"wizarding\",\"allowed\",\"form\",\"fun\",\"remembered\",\"tone\",\"afraid\",\"filled\",\"entered\",\"picked\",\"anger\",\"glad\",\"touch\",\"broke\",\"quick\",\"step\",\"silent\",\"nose\",\"truth\",\"play\",\"grin\",\"meeting\",\"cried\",\"hey\",\"laughing\",\"auror\",\"important\",\"smirked\",\"certain\",\"warm\",\"empty\",\"none\",\"became\",\"team\",\"weeks\",\"high\",\"using\",\"food\",\"percy\",\"older\",\"fleur\",\"hate\",\"expected\",\"wide\",\"threw\",\"cheek\",\"breakfast\",\"yelled\",\"worse\",\"elf\",\"problem\",\"perfect\",\"teddy\",\"ones\",\"cloak\",\"clearly\",\"n\",\"memories\",\"waited\",\"shock\",\"obviously\",\"liked\",\"ten\",\"wife\",\"alive\",\"arrived\",\"sometimes\",\"riddle\",\"certainly\",\"note\",\"carefully\",\"summer\",\"despite\",\"glass\",\"job\",\"gotten\",\"information\",\"wrapped\",\"daphne\",\"loud\",\"forced\",\"madam\",\"except\",\"ear\",\"strong\",\"clothes\",\"tomorrow\",\"battle\",\"library\",\"tea\",\"deal\",\"strange\",\"trouble\",\"calm\",\"worked\",\"minute\",\"confused\",\"owl\",\"middle\",\"headed\",\"easy\",\"evening\",\"normal\",\"daughter\",\"mine\",\"shirt\",\"parchment\",\"lay\",\"secret\",\"seems\",\"makes\",\"twins\",\"paused\",\"apparently\",\"notice\",\"line\",\"tired\",\"suppose\",\"moments\",\"broom\",\"somehow\",\"led\",\"tongue\",\"broken\",\"usual\",\"lying\",\"promise\",\"cup\",\"piece\",\"pale\",\"men\",\"arthur\",\"chuckled\",\"familiar\",\"sounded\",\"questions\",\"game\",\"attack\",\"doubt\",\"mate\",\"muggles\",\"mad\",\"save\",\"wonder\",\"means\",\"finger\",\"bright\",\"helped\",\"uncle\",\"bella\",\"explain\",\"aurors\",\"pressed\",\"gasped\",\"minister\",\"third\",\"jumped\",\"charms\",\"hissed\",\"situation\",\"hospital\",\"whether\",\"position\",\"lifted\",\"glared\",\"manor\",\"moody\",\"covered\",\"fast\",\"catch\",\"shall\",\"seconds\",\"wants\",\"often\",\"asleep\",\"asking\",\"early\",\"dobby\",\"teeth\",\"pomfrey\",\"listen\",\"wearing\",\"neither\",\"al\",\"bag\",\"write\",\"follow\",\"kingsley\",\"following\",\"sigh\",\"forget\",\"letting\",\"besides\",\"screamed\",\"soul\",\"truly\",\"pull\",\"mark\",\"student\",\"ended\",\"beginning\",\"keeping\",\"fighting\",\"hoped\",\"playing\",\"flew\",\"likely\",\"silver\",\"brown\",\"wondering\",\"eyebrow\",\"husband\",\"guys\",\"easily\",\"lip\",\"direction\",\"usually\",\"hot\",\"learn\",\"hated\",\"crying\",\"future\",\"ah\",\"starting\",\"edge\",\"somewhere\",\"eat\",\"enjoy\",\"flying\",\"six\",\"self\",\"azkaban\",\"low\",\"shocked\",\"offered\",\"cheeks\",\"cry\",\"hoping\",\"falling\",\"damn\",\"age\",\"powerful\",\"tightly\",\"hide\",\"serious\",\"earlier\",\"send\",\"knees\",\"money\",\"train\",\"drink\",\"missed\",\"pair\",\"ravenclaw\",\"pocket\",\"disappeared\",\"speaking\",\"choice\",\"god\",\"lived\",\"aware\",\"single\",\"spot\",\"expect\",\"definitely\",\"wake\",\"handed\",\"putting\",\"present\",\"eventually\",\"hug\",\"aunt\",\"bedroom\",\"forest\",\"mirror\",\"killing\",\"ears\",\"dress\",\"simple\",\"scared\",\"check\",\"waved\",\"laughter\",\"paper\",\"continue\",\"admit\",\"join\",\"sounds\",\"exclaimed\",\"feelings\",\"force\",\"breathing\",\"blinked\",\"corridor\",\"box\",\"slipped\",\"relief\",\"showed\",\"forehead\",\"sleeping\",\"writing\",\"smirk\",\"doors\",\"younger\",\"final\",\"news\",\"wands\",\"cannot\",\"murmured\",\"protect\",\"causing\",\"ok\",\"ball\",\"bathroom\",\"indeed\",\"snake\",\"kissing\",\"twenty\",\"wards\",\"dangerous\",\"steps\",\"business\",\"seamus\",\"lunch\",\"dean\",\"glance\",\"evil\",\"obvious\",\"alley\",\"cause\",\"entrance\",\"dream\",\"sudden\",\"party\",\"stayed\",\"ring\",\"cedric\",\"married\",\"busy\",\"foot\",\"apart\",\"dragon\",\"visit\",\"touched\",\"fuck\",\"honestly\",\"difficult\",\"needs\",\"fault\",\"imagine\",\"drew\",\"number\",\"blonde\",\"stuff\",\"burst\",\"leaning\",\"walls\",\"aside\",\"human\",\"groaned\",\"slytherins\",\"crowd\",\"darkness\",\"interrupted\",\"hello\",\"couch\",\"silently\",\"odd\",\"teacher\",\"learned\",\"remained\",\"tower\",\"stated\",\"werewolf\",\"match\",\"stuck\",\"ahead\",\"lavender\",\"date\",\"tight\",\"growled\",\"wanting\",\"spend\",\"allow\",\"born\",\"lose\",\"points\",\"finish\",\"relationship\",\"grew\",\"act\",\"heavy\",\"hiding\",\"realised\",\"regulus\",\"umbridge\",\"response\",\"shop\",\"crossed\"],\"x1\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]},\"x2\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[1000]}},\"selected\":{\"id\":\"1046\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1045\",\"type\":\"UnionRenderers\"}},\"id\":\"1032\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"formatter\":{\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},\"ticker\":{\"id\":\"1014\",\"type\":\"BasicTicker\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1023\",\"type\":\"PanTool\"},{\"id\":\"1024\",\"type\":\"WheelZoomTool\"},{\"id\":\"1025\",\"type\":\"ResetTool\"},{\"id\":\"1026\",\"type\":\"SaveTool\"}]},\"id\":\"1027\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1034\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1035\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1037\",\"type\":\"CDSView\"}},\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":\"fasttext T-SNE (top 1000 words)\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{\"source\":{\"id\":\"1032\",\"type\":\"ColumnDataSource\"}},\"id\":\"1037\",\"type\":\"CDSView\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"94e78dac-6b4b-425b-87c8-a83895eb773d\",\"roots\":{\"1002\":\"e429f415-0213-434a-9ae9-c28672d77ff7\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tsne(top_words_tsne, top_words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPAC_CORPUS_DIR = 'hpac_corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(HPAC_CORPUS_DIR, 'hpac_training_128.tsv')\n",
    "TEST_PATH = os.path.join(HPAC_CORPUS_DIR, 'hpac_test_128.tsv')\n",
    "DEV_PATH = os.path.join(HPAC_CORPUS_DIR, 'hpac_dev_128.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'RIDDIKULUS': 616,\n",
       "         'STUPEFY': 3326,\n",
       "         'ACCIO': 4168,\n",
       "         'EXPELLIARMUS': 2728,\n",
       "         'PROTEGO': 1396,\n",
       "         'LUMOS': 3894,\n",
       "         'CRUCIO': 7378,\n",
       "         'REDUCTO': 1159,\n",
       "         'AVADA_KEDAVRA': 7491,\n",
       "         'WINGARDIUM_LEVIOSA': 1178,\n",
       "         'SCOURGIFY': 1244,\n",
       "         'PETRIFICUS_TOTALUS': 1134,\n",
       "         'INCENDIO': 1238,\n",
       "         'DEPRIMO': 50,\n",
       "         'IMPERIO': 1180,\n",
       "         'EVANESCO': 459,\n",
       "         'ALOHOMORA': 1263,\n",
       "         'EXPECTO_PATRONUM': 1657,\n",
       "         'REDUCIO': 104,\n",
       "         'OBLIVIATE': 2891,\n",
       "         'SONORUS': 410,\n",
       "         'SECTUMSEMPRA': 1458,\n",
       "         'CONFRINGO': 314,\n",
       "         'LEGILIMENS': 1725,\n",
       "         'DIFFINDO': 491,\n",
       "         'TARANTALLEGRA': 120,\n",
       "         'OPPUGNO': 133,\n",
       "         'COLLOPORTUS': 246,\n",
       "         'APARECIUM': 57,\n",
       "         'IMPEDIMENTA': 491,\n",
       "         'TERGEO': 216,\n",
       "         'MUFFLIATO': 923,\n",
       "         'INCARCEROUS': 606,\n",
       "         'RELASHIO': 153,\n",
       "         'SILENCIO': 1056,\n",
       "         'LEVICORPUS': 488,\n",
       "         'LOCOMOTOR': 165,\n",
       "         'AVIS': 150,\n",
       "         'MORSMORDRE': 206,\n",
       "         'PROTEGO_TOTALUM': 37,\n",
       "         'REPARO': 1036,\n",
       "         'AGUAMENTI': 746,\n",
       "         'EPISKEY': 368,\n",
       "         'NOX': 638,\n",
       "         'MOBILICORPUS': 167,\n",
       "         'PORTUS': 222,\n",
       "         'FINITE_INCANTATEM': 644,\n",
       "         'LANGLOCK': 79,\n",
       "         'IMPERVIUS': 138,\n",
       "         'ENGORGIO': 315,\n",
       "         'CAVE_INIMICUM': 16,\n",
       "         'SALVIO_HEXIA': 31,\n",
       "         'RENNERVATE': 212,\n",
       "         'POINT_ME': 388,\n",
       "         'DENSAUGEO': 64,\n",
       "         'QUIETUS': 104,\n",
       "         'GEMINIO': 75,\n",
       "         'FERULA': 74,\n",
       "         'HOMENUM_REVELIO': 167,\n",
       "         'ORCHIDEOUS': 72,\n",
       "         'LOCOMOTOR_MORTIS': 116,\n",
       "         'CONFUNDO': 112,\n",
       "         'DELETRIUS': 56,\n",
       "         'EXPULSO': 166,\n",
       "         'OBSCURO': 54,\n",
       "         'PRIOR_INCANTATO': 49,\n",
       "         'RICTUSEMPRA': 152,\n",
       "         'SPECIALIS_REVELIO': 42,\n",
       "         'FLAGRATE': 49,\n",
       "         'PIERTOTUM_LOCOMOTOR': 27,\n",
       "         'DEFODIO': 30,\n",
       "         'FURNUNCULUS': 130,\n",
       "         'WADDIWASI': 44,\n",
       "         'METEOLOJINX_RECANTO': 10,\n",
       "         'PROTEGO_HORRIBILIS': 15,\n",
       "         'LIBERACORPUS': 54,\n",
       "         'SERPENSORTIA': 115,\n",
       "         'REPELLO_MUGGLETUM': 20,\n",
       "         'ANAPNEO': 59,\n",
       "         'DURO': 33,\n",
       "         'MOBILIARBUS': 24,\n",
       "         'GLISSEO': 24,\n",
       "         'DESCENDO': 17,\n",
       "         'ERECTO': 23,\n",
       "         'PESKIPIKSI_PESTERNOMI': 4})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH, names=['n', 'label', 'text'], sep='\\t')\n",
    "\n",
    "Counter(train_df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы не сбалансированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_PATH, names=['n', 'label', 'text'], sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация и паддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(texts, max_size):\n",
    "    padded = []\n",
    "    for text in tqdm(texts):\n",
    "        text = text.split()\n",
    "        if len(text) >= max_size:\n",
    "            padded.append(text[:max_size])\n",
    "        else:\n",
    "            text += ['']*(max_size - len(text))\n",
    "            padded.append(text)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_texts(texts, pool):\n",
    "    processed = list(tqdm(pool.imap(lemmatize_sentence, texts), total=len(texts)))\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_and_pad(texts, sentence_size, pool):\n",
    "    lemmatized = lemmatize_texts(texts, pool)\n",
    "    lemmatized_and_padded = padding(lemmatized, sentence_size)\n",
    "    return lemmatized_and_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f403c35258e749118386a735f5995bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f517957fa6e42f7823d2bf0ca505e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5.67 s, sys: 1.46 s, total: 7.13 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_padded = lemmatize_and_pad(train_df.text.to_list(), sentence_size, global_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a84b68c6cfa4c58a55073cb84b3a9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7679.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a600141bb6c64a00986aeb67dfab880a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7679.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 749 ms, sys: 197 ms, total: 946 ms\n",
      "Wall time: 2.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_padded = lemmatize_and_pad(test_df.text.to_list(), sentence_size, global_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение эмбеддингов слов и label'ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeds(model, padded):\n",
    "    return np.array([\n",
    "        [\n",
    "            model[word] for word in sentence\n",
    "        ]\n",
    "        for sentence in tqdm(padded)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378986f55dbc42f581d9b60f85409814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = get_embeds(ft_model, train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77341a78f3154e93b7a57d26ac47fc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7679.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = get_embeds(ft_model, test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 128, 256)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('X_train_test.bin', 'wb') as out_f:\n",
    "#     pickle.dump((X_train, X_test), out_f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train_test.bin', 'rb') as in_f:\n",
    "    X_train, X_test = pickle.load(out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_column = train_df.label.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.fit(labels_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_vectors(list_values):\n",
    "    return label_encoder.transform(np.array(list_values).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_to_labels(list_vectors):\n",
    "    if isinstance(list_vectors, scipy.sparse.csr.csr_matrix):\n",
    "        list_vectors = list_vectors.toarray()\n",
    "    return label_encoder.inverse_transform(np.array(list_vectors))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = labels_to_vectors(train_df.label).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labels_to_vectors(test_df.label).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бейзлайн (fastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, name):\n",
    "    df = pd.read_csv(path, sep='\\t', names=['n', 'label', 'text'])\n",
    "    df['label'] = df['label'].apply(lambda x: '__label__' + str(x))\n",
    "    df[['label', 'text']].to_csv(name, header=False, index=False, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data(TRAIN_PATH, 'train.txt')\n",
    "prepare_data(TEST_PATH, 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_prepared = pd.read_csv(TEST_PATH, names=['n', 'label', 'text'], sep='\\t')\n",
    "test_df_prepared['label'].apply(lambda x: '__label__' + str(x))\n",
    "y_true = test_df_prepared.label.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fasttext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fasttext' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "baseline = fasttext.train_supervised('train.txt', \n",
    "                                    epoch=50,\n",
    "                                    dim=256, \n",
    "                                    thread=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline.predict(test_df.text.to_list())[0]\n",
    "y_pred = np.array(y_pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10311622328060388"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2748586054828659"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30055996874593044"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.32347961974215395\n",
      "R@1: 0.32347961974215395\n"
     ]
    }
   ],
   "source": [
    "result = baseline.test('test.txt')\n",
    "\n",
    "print('P@1:', result[1])\n",
    "print('R@1:', result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аугментация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over and under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ulyanin/jupyter-notebook/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                    NearMiss, \n",
    "                                    InstanceHardnessThreshold,\n",
    "                                    CondensedNearestNeighbour,\n",
    "                                    EditedNearestNeighbours,\n",
    "                                    RepeatedEditedNearestNeighbours,\n",
    "                                    AllKNN,\n",
    "                                    NeighbourhoodCleaningRule,\n",
    "                                    OneSidedSelection,\n",
    "                                    TomekLinks)\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 32768)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 85)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=42, n_jobs=56)\n",
    "# X_smote, y_smote = sm.fit_sample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "\n",
    "# with open('X_y_smote.bin', 'wb') as out_f:\n",
    "#     pickle.dump([X_smote, y_smote], out_f, protocol=4)\n",
    "    \n",
    "tomek = TomekLinks(n_jobs=10)\n",
    "X_tomek, y_tomek = tomek.fit_sample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "\n",
    "# with open('X_y_tomek.bin', 'wb') as out_f:\n",
    "#     pickle.dump([X_tomek, y_tomek], out_f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_y_tomek.bin', 'rb') as in_f:\n",
    "    X_tomek, y_tomek = pickle.load(in_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60722, 32768), (60722, 85))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tomek.shape, y_tomek.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counter = Counter(train_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PESKIPIKSI_PESTERNOMI', 4),\n",
       " ('METEOLOJINX_RECANTO', 10),\n",
       " ('PROTEGO_HORRIBILIS', 15),\n",
       " ('CAVE_INIMICUM', 16),\n",
       " ('DESCENDO', 17),\n",
       " ('REPELLO_MUGGLETUM', 20),\n",
       " ('ERECTO', 23),\n",
       " ('MOBILIARBUS', 24),\n",
       " ('GLISSEO', 24),\n",
       " ('PIERTOTUM_LOCOMOTOR', 27)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(label_counter.items(), key=lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.0"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(label_counter.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В самом редком классе 4 примера, поэтому параметр n_neighbours в SMOTE должен быть меньше или равен 4, это мало. Мы выкинем этот класс из трейна и оставим n_neighbours дефолтным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_indices = train_df.label == 'PESKIPIKSI_PESTERNOMI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_, y_smote_ = X_train[~bad_indices], y_train[~bad_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 23min 55s, sys: 7min 43s, total: 5h 31min 38s\n",
      "Wall time: 21min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm = SMOTE(random_state=42, n_jobs=56)\n",
    "X_smote, y_smote = sm.fit_sample(X_smote_.reshape(X_smote_.shape[0], -1), y_smote_)\n",
    "\n",
    "# with open('X_y_smote.bin', 'wb') as out_f:\n",
    "#     pickle.dump([X_smote, y_smote], out_f, protocol=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_y_smote.bin', 'rb') as out_f:\n",
    "    X_smote, y_smote = pickle.load(out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 32768)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tomek = X_tomek.reshape(-1, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote = X_smote.reshape(-1, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tomek_labels = vectors_to_labels(y_tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60976, 85)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 128, 256)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-320:\n",
      "Process ForkPoolWorker-322:\n",
      "Process ForkPoolWorker-302:\n",
      "Process ForkPoolWorker-301:\n",
      "Process ForkPoolWorker-307:\n",
      "Process ForkPoolWorker-319:\n",
      "Process ForkPoolWorker-309:\n",
      "Process ForkPoolWorker-305:\n",
      "Process ForkPoolWorker-321:\n",
      "Process ForkPoolWorker-300:\n",
      "Process ForkPoolWorker-315:\n",
      "Process ForkPoolWorker-303:\n",
      "Process ForkPoolWorker-289:\n",
      "Process ForkPoolWorker-323:\n",
      "Process ForkPoolWorker-293:\n",
      "Process ForkPoolWorker-290:\n",
      "Process ForkPoolWorker-308:\n",
      "Process ForkPoolWorker-298:\n",
      "Process ForkPoolWorker-299:\n",
      "Process ForkPoolWorker-313:\n",
      "Process ForkPoolWorker-281:\n",
      "Process ForkPoolWorker-296:\n",
      "Process ForkPoolWorker-312:\n",
      "Process ForkPoolWorker-292:\n",
      "Process ForkPoolWorker-304:\n",
      "Process ForkPoolWorker-294:\n",
      "Process ForkPoolWorker-291:\n",
      "Process ForkPoolWorker-310:\n",
      "Process ForkPoolWorker-318:\n",
      "Process ForkPoolWorker-282:\n",
      "Process ForkPoolWorker-285:\n",
      "Process ForkPoolWorker-306:\n",
      "Process ForkPoolWorker-316:\n",
      "Process ForkPoolWorker-297:\n",
      "Process ForkPoolWorker-286:\n",
      "Process ForkPoolWorker-288:\n",
      "Process ForkPoolWorker-287:\n",
      "Process ForkPoolWorker-317:\n",
      "Process ForkPoolWorker-284:\n",
      "Process ForkPoolWorker-314:\n",
      "Process ForkPoolWorker-311:\n",
      "Process ForkPoolWorker-283:\n",
      "Process ForkPoolWorker-295:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-324:\n",
      "Process ForkPoolWorker-327:\n",
      "Process ForkPoolWorker-329:\n",
      "Process ForkPoolWorker-335:\n",
      "Process ForkPoolWorker-328:\n",
      "Process ForkPoolWorker-332:\n",
      "Process ForkPoolWorker-330:\n",
      "Process ForkPoolWorker-331:\n",
      "Process ForkPoolWorker-326:\n",
      "Process ForkPoolWorker-325:\n",
      "Process ForkPoolWorker-338:\n",
      "Process ForkPoolWorker-339:\n",
      "Process ForkPoolWorker-334:\n",
      "Process ForkPoolWorker-336:\n",
      "Process ForkPoolWorker-333:\n",
      "Process ForkPoolWorker-337:\n",
      "Process ForkPoolWorker-340:\n",
      "Process ForkPoolWorker-341:\n",
      "Process ForkPoolWorker-342:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-347:\n",
      "Process ForkPoolWorker-348:\n",
      "Process ForkPoolWorker-344:\n",
      "Process ForkPoolWorker-349:\n",
      "Process ForkPoolWorker-343:\n",
      "Process ForkPoolWorker-350:\n",
      "Process ForkPoolWorker-345:\n",
      "Process ForkPoolWorker-351:\n",
      "Process ForkPoolWorker-352:\n",
      "Process ForkPoolWorker-353:\n",
      "Process ForkPoolWorker-354:\n",
      "Process ForkPoolWorker-356:\n",
      "Process ForkPoolWorker-355:\n",
      "Process ForkPoolWorker-346:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X_tomek.reshape(X_tomek.shape[0], -1), y_tomek)\n",
    "\n",
    "\n",
    "with open('X_y_ros_over_tomek.bin', 'wb') as out_f:\n",
    "    pickle.dump([X_ros, y_ros], out_f, protocol=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros = X_ros.reshape(-1, 128, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_synonyms_text(text, p=0.75):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        rand = np.random.randint(100)\n",
    "        new_word = word\n",
    "\n",
    "        if rand <= p*100:            \n",
    "            syns = wn.synsets(word)\n",
    "            if syns:\n",
    "                meaning = np.random.choice(syns, 1)[0]\n",
    "                means = meaning.lemmas()\n",
    "                choice = np.random.choice(means, 1)[0]\n",
    "                new_word = choice.name().lower()\n",
    "                new_word = new_word.replace('_', ' ')\n",
    "                new_word = lemmatize_word(new_word)\n",
    "                print(word, new_word)\n",
    "                \n",
    "        new_text.append(new_word)\n",
    "        \n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_via_wordnet(sentences, labels, min_length=200, p=0.5):\n",
    "    labels_cnt = Counter(labels)\n",
    "    assert len(sentences) == len(labels)\n",
    "    sort()\n",
    "    for i in range(sentences.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.0"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(label_counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = train_df.text.to_list()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deception'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('magic')[1].lemmas()[-1].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('magic.n.01'), Synset('magic_trick.n.01'), Synset('charming.s.02')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('magic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self, filter_sizes, output_shape, n_filters, drop_out_koef):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = [\n",
    "            layers.Conv2D(n_filters, (filter_size, embed_dim),\n",
    "                                   activation='relu',\n",
    "                                   input_shape=(sentence_size, embed_dim, 1))\n",
    "            for filter_size in filter_sizes\n",
    "        ]\n",
    "        \n",
    "        self.max_pools = [\n",
    "            layers.MaxPooling2D(pool_size=(sentence_size - filter_size, 1))\n",
    "            for filter_size in filter_sizes\n",
    "        ]\n",
    "        \n",
    "        self.drop_out = layers.Dropout(drop_out_koef)\n",
    "        self.dense = layers.Dense(output_shape, activation='softmax',\n",
    "                                  input_shape=(None, len(filter_sizes)*n_filters))\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        convs = [conv(inputs) for conv in self.convs]\n",
    "        max_pools = [max_pool(conv) for conv, max_pool in zip(convs, self.max_pools)]\n",
    "        \n",
    "        concatenation = tf.concat(max_pools, axis=-1)\n",
    "        concatenation = tf.squeeze(concatenation, [1, 2])\n",
    "\n",
    "        drop_out = self.drop_out(concatenation)\n",
    "\n",
    "        return self.dense(drop_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "output_shape = len(set(labels))\n",
    "embed_dim = 256\n",
    "sentence_size = 128\n",
    "\n",
    "filter_sizes = [3, 3, 4, 4, 5, 5]\n",
    "n_filters = 100\n",
    "drop_out_koef = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = CNN(filter_sizes, output_shape, n_filters, drop_out_koef)\n",
    "    model.build(input_shape=(None, sentence_size, embed_dim, 1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           multiple                  76900     \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           multiple                  76900     \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           multiple                  102500    \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           multiple                  102500    \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           multiple                  128100    \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           multiple                  128100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  51085     \n",
      "=================================================================\n",
      "Total params: 666,085\n",
      "Trainable params: 666,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(train, test):\n",
    "    epoch_count = range(1, len(train) + 1)\n",
    "\n",
    "    plt.plot(epoch_count, train)\n",
    "    plt.plot(epoch_count, test)\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(current_model, model_name, X, y):\n",
    "    if len(X.shape) != 4:\n",
    "        X = X[:, :, :, np.newaxis]\n",
    "    \n",
    "    y_int = [y_.argmax() for y_ in y]\n",
    "    class_weight = compute_sample_weight('balanced', np.unique(y_int), y_int)\n",
    "    \n",
    "    checkpoint_path = f'training_tf_cnn/cnn-{model_name}'\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    save_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, monitor='val_loss', verbose=1,\n",
    "        save_best_only=True, save_weights_only=False\n",
    "    )\n",
    "    \n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    for batch_size in [512, 256, 128, 64]:\n",
    "        print(batch_size)\n",
    "        history = current_model.fit(X, y,\n",
    "                                    validation_data=(X_test, y_test),\n",
    "                                    callbacks=[save_checkpoint],\n",
    "                                    epochs=2,\n",
    "                                    class_weight=class_weight,\n",
    "                                    batch_size=batch_size)\n",
    "\n",
    "        train_acc.extend(history.history['acc'])\n",
    "        test_acc.extend(history.history['val_acc'])\n",
    "        \n",
    "    plot_history(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "WARNING:tensorflow:Entity <bound method CNN.call of <__main__.CNN object at 0x7f2d501418d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method CNN.call of <__main__.CNN object at 0x7f2d501418d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method CNN.call of <__main__.CNN object at 0x7f2d501418d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method CNN.call of <__main__.CNN object at 0x7f2d501418d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Train on 633760 samples, validate on 7679 samples\n",
      "Epoch 1/2\n",
      "633344/633760 [============================>.] - ETA: 0s - loss: 2.1172 - acc: 0.5294\n",
      "Epoch 00001: val_loss improved from inf to 3.10780, saving model to training_tf_cnn/cnn-cnn_tomek_over\n",
      "633760/633760 [==============================] - 348s 549us/sample - loss: 2.1167 - acc: 0.5295 - val_loss: 3.1078 - val_acc: 0.2306\n",
      "Epoch 2/2\n",
      "633344/633760 [============================>.] - ETA: 0s - loss: 1.0932 - acc: 0.7321\n",
      "Epoch 00002: val_loss improved from 3.10780 to 3.03121, saving model to training_tf_cnn/cnn-cnn_tomek_over\n",
      "633760/633760 [==============================] - 349s 550us/sample - loss: 1.0930 - acc: 0.7321 - val_loss: 3.0312 - val_acc: 0.2551\n",
      "256\n",
      "Train on 633760 samples, validate on 7679 samples\n",
      "Epoch 1/2\n",
      "633600/633760 [============================>.] - ETA: 0s - loss: 0.8412 - acc: 0.7855\n",
      "Epoch 00001: val_loss did not improve from 3.03121\n",
      "633760/633760 [==============================] - 330s 521us/sample - loss: 0.8411 - acc: 0.7855 - val_loss: 3.1285 - val_acc: 0.2590\n",
      "Epoch 2/2\n",
      "633600/633760 [============================>.] - ETA: 0s - loss: 0.6589 - acc: 0.8276\n",
      "Epoch 00002: val_loss did not improve from 3.03121\n",
      "633760/633760 [==============================] - 328s 518us/sample - loss: 0.6588 - acc: 0.8276 - val_loss: 3.2227 - val_acc: 0.2763\n",
      "128\n",
      "Train on 633760 samples, validate on 7679 samples\n",
      "Epoch 1/2\n",
      "633728/633760 [============================>.] - ETA: 0s - loss: 0.6143 - acc: 0.8369\n",
      "Epoch 00001: val_loss did not improve from 3.03121\n",
      "633760/633760 [==============================] - 310s 489us/sample - loss: 0.6143 - acc: 0.8369 - val_loss: 3.4551 - val_acc: 0.2627\n",
      "Epoch 2/2\n",
      "633728/633760 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8581\n",
      "Epoch 00002: val_loss did not improve from 3.03121\n",
      "633760/633760 [==============================] - 309s 488us/sample - loss: 0.5246 - acc: 0.8581 - val_loss: 3.5894 - val_acc: 0.2739\n",
      "64\n",
      "Train on 633760 samples, validate on 7679 samples\n",
      "Epoch 1/2\n",
      "633664/633760 [============================>.] - ETA: 0s - loss: 0.5468 - acc: 0.8518\n",
      "Epoch 00001: val_loss did not improve from 3.03121\n",
      "633760/633760 [==============================] - 334s 528us/sample - loss: 0.5468 - acc: 0.8518 - val_loss: 3.8236 - val_acc: 0.2645\n",
      "Epoch 2/2\n",
      "633664/633760 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8648\n",
      "Epoch 00002: val_loss did not improve from 3.03121\n",
      "633760/633760 [==============================] - 327s 517us/sample - loss: 0.4928 - acc: 0.8648 - val_loss: 4.0492 - val_acc: 0.2661\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, 'cnn_tomek_over', X_ros, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vectors_to_labels(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_check = vectors_to_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1598903687741231"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_check, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25828000956667574"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_check, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.266050266961844"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_check, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_model(current_model, model_name, X, y):\n",
    "    train_model(model, 'cnn_tomek_over', X_ros, y_ros)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = vectors_to_labels(y_pred)\n",
    "    y_check = vectors_to_labels(y_test)\n",
    "    f1_macro = f1_score(y_check, y_pred, average='macro')\n",
    "    f1_weighted = f1_score(y_check, y_pred, average='weighted')\n",
    "    f1_micro = f1_score(y_check, y_pred, average='micro')\n",
    "    print(f'f1_macro = {f1_macro}')\n",
    "    print(f'f1_weighted = {f1_weighted}')\n",
    "    print(f'f1_micro = {f1_micro}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 128\n",
    "dropout_koef = 0.3\n",
    "dense_koef = 64\n",
    "\n",
    "output_shape = len(set(labels))\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = models.Sequential()\n",
    "\n",
    "lstm_model.add(layers.Bidirectional(\n",
    "    layers.LSTM(units, return_sequences=False),\n",
    "    input_shape=(sentence_size, embed_dim)\n",
    "))\n",
    "lstm_model.add(layers.Dense(dense_koef, activation='relu'))\n",
    "lstm_model.add(layers.Dropout(drop_out_koef))\n",
    "lstm_model.add(layers.Dense(output_shape, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_16 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 85)                5525      \n",
      "=================================================================\n",
      "Total params: 416,213\n",
      "Trainable params: 416,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"training_tf_bilstm/bilstm-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath=checkpoint_path, \n",
    "                                verbose=1, \n",
    "                                save_weights_only=True,\n",
    "                                period=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ = X_train.squeeze()\n",
    "# X_test_ = X_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 59s 972us/sample - loss: 3.5737 - acc: 0.1378 - val_loss: 3.1786 - val_acc: 0.1921\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 58s 945us/sample - loss: 3.1671 - acc: 0.1956 - val_loss: 3.0056 - val_acc: 0.2404\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 71s 1ms/sample - loss: 3.0230 - acc: 0.2391 - val_loss: 2.8828 - val_acc: 0.2655\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 71s 1ms/sample - loss: 2.8967 - acc: 0.2752 - val_loss: 2.7552 - val_acc: 0.3020\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 100s 2ms/sample - loss: 2.8507 - acc: 0.2835 - val_loss: 2.7490 - val_acc: 0.2969\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 99s 2ms/sample - loss: 2.7659 - acc: 0.3039 - val_loss: 2.6808 - val_acc: 0.3222\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 159s 3ms/sample - loss: 2.7427 - acc: 0.3077 - val_loss: 2.6535 - val_acc: 0.3260\n",
      "Train on 60980 samples, validate on 7679 samples\n",
      "60980/60980 [==============================] - 158s 3ms/sample - loss: 2.6525 - acc: 0.3289 - val_loss: 2.6257 - val_acc: 0.3331\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [512, 512, 256, 256, 128, 128, 64, 64]:\n",
    "    history = lstm_model.fit(X_train_, y_train,\n",
    "                        validation_data=(X_test_, y_test),\n",
    "#                         callbacks=[cp_callback],\n",
    "                        epochs=1,\n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vectors_to_labels(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_check = vectors_to_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06904786801430506"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_check, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2748260210111838"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_check, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33311629118374786"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_check, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
