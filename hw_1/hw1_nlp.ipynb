{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1\n",
    "## Harry Potter and the Action Prediction Challenge from Natural Language\n",
    "\n",
    "*deadline*: 9 марта 2020, 23:30\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом Harry Potter and the Action Prediction Challenge. Корпус собран из фанфиков о Гарри Поттере и состоит из двух частей: 1) сырые тексты, 2) фрагменты текстов, описывающих ситуацию, в которой произнесено заклинание.\n",
    "\n",
    "Корпус описан в статье: https://arxiv.org/pdf/1905.11037.pdf\n",
    "\n",
    "David Vilares and Carlos Gómez-Rodríguez. Harry Potter and the Action Prediction Challenge from Natural Language. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics. To appear.\n",
    "\n",
    "Код для сбора корпуса находится в репозитории: https://github.com/aghie/hpac . Корпус можно скачать по инструкции из этого репозитория, но для экономии времени авторы задания уже скачали и подготовили данные к работе. \n",
    "\n",
    "Ссылки на собранный корпус: \n",
    "* Сырые тексты:  https://www.dropbox.com/s/23xet9kvbqna1qs/hpac_raw.zip?dl=0\n",
    "* Токенизированные тексты в нижнем регистре: https://www.dropbox.com/s/gwfgmomdbetvdye/hpac_lower_tokenized.zip?dl=0\n",
    "* train-test-dev: https://www.dropbox.com/s/3vdz0mouvex8abd/hpac_splits.zip?dl=0\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах (сырых или предобработанных -- на ваше усмотрение), Часть 3 – на разбиение на тестовое, отладочное и обучающее множества. Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "В статье и репозитории вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и переиспользовать. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 3-х человек.\n",
    "2. Домашнее задание сдается через anytask, инвайты будут дополнительно высланы.\n",
    "3. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо ipython-тетрадке. \n",
    "4. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "5. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "6. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "7. Плагиат и любое недобросоветсное цитирование приводит к обнуление оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-1000 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия. \n",
    "\n",
    "[бонус] Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса HPAC.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-1000 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: данный фрагмент фанфика описывают какую-то ситуацию, которая предшествует произнесению заклинания. Требуется по тексту предсказать, какое именно заклинание будет произнесено. Таким образом, заклинание - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на частых и редких классах. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом заклинаний?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 500-1000 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Читали ли вы сами Гарри Поттера или фанфики о нем и помогло ли вам знание предметной области в выполнении домашнего задания?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "Сырые тексты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !unzip hpac_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'hpac_raw': No such file or directory\r\n",
      "0\r\n"
     ]
    }
   ],
   "source": [
    "!ls hpac_raw | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip hpac_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('hpac_corpus/hpac_training_128.tsv', sep = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7642954.0.676</td>\n",
       "      <td>RIDDIKULUS</td>\n",
       "      <td>were staring at her . she was up next to face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10443333.0.5753</td>\n",
       "      <td>RIDDIKULUS</td>\n",
       "      <td>that whole time . her first reaction , for whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4703706.0.8690</td>\n",
       "      <td>STUPEFY</td>\n",
       "      <td>we watched his inglorious withdrawal together ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4593427.0.1815</td>\n",
       "      <td>ACCIO</td>\n",
       "      <td>my wand , `` incendio . '' this wretched chill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4278446.0.2692</td>\n",
       "      <td>EXPELLIARMUS</td>\n",
       "      <td>already compared ours , they 're the same ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1  \\\n",
       "0    7642954.0.676    RIDDIKULUS   \n",
       "1  10443333.0.5753    RIDDIKULUS   \n",
       "2   4703706.0.8690       STUPEFY   \n",
       "3   4593427.0.1815         ACCIO   \n",
       "4   4278446.0.2692  EXPELLIARMUS   \n",
       "\n",
       "                                                   2  \n",
       "0  were staring at her . she was up next to face ...  \n",
       "1  that whole time . her first reaction , for whi...  \n",
       "2  we watched his inglorious withdrawal together ...  \n",
       "3  my wand , `` incendio . '' this wretched chill...  \n",
       "4  already compared ours , they 're the same ever...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RIDDIKULUS',\n",
       " \"were staring at her . she was up next to face the boggart in defense against the dark arts class . she was not scared , but what she was worried about was what had happened with lysander . she looked up at the boggart in front of her which had previously been a humongous spider . its eyes locked on her . before she could think of what frightened her , the spider transformed into lysander . he was dying . there were giggles coming from the male and female hufflepuff students . there was a smirk on lorcan 's face . `` lily help me '' i ca n't fail this class because of a secret love . lily lifted her wand and said , ``\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][1], df.iloc[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как использовать WordNet из nltk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем WordNet\n",
    "import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('magic.n.01'), Synset('magic_trick.n.01'), Synset('charming.s.02')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слово -> множество синсетов (синонимов разных смыслов исходного слова)\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('magic_trick.n.01.magic_trick')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим, что внутри одного синсета\n",
    "wn.synsets('magic')[1].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deception'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем лемму одного из слов из синсета\n",
    "wn.synsets('magic')[1].lemmas()[-1].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Топ-1000 слов по частоте без учета стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/darya/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')\n",
    "RAW_TEXTS_DIR = 'fanfiction_texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36225/36225 [18:34<00:00, 32.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "word_count = defaultdict(int)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for path in tqdm(os.listdir(RAW_TEXTS_DIR)):\n",
    "    full_path = os.path.join(RAW_TEXTS_DIR, path)\n",
    "    with open(full_path, 'r') as f:\n",
    "        for line in f:\n",
    "            words = tokenizer.tokenize(line.strip())\n",
    "            for word in words:\n",
    "                word = word.lower()\n",
    "                if word not in STOPWORDS:\n",
    "                    word_count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('top_1000.pickle', 'wb') as f:\n",
    "#     pickle.dump(top_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harry', 4000488),\n",
       " ('said', 2262364),\n",
       " ('hermione', 1831464),\n",
       " ('would', 1655264),\n",
       " ('back', 1400308),\n",
       " ('one', 1400054),\n",
       " ('draco', 1389966),\n",
       " ('could', 1303069),\n",
       " ('like', 1275300),\n",
       " ('know', 1203948),\n",
       " ('eyes', 1033469),\n",
       " ('time', 1016958),\n",
       " ('ron', 906181),\n",
       " ('looked', 893445),\n",
       " ('get', 847651),\n",
       " ('asked', 826495),\n",
       " ('well', 802448),\n",
       " ('even', 770242),\n",
       " ('around', 767637),\n",
       " ('see', 744540),\n",
       " ('head', 737080),\n",
       " ('going', 718863),\n",
       " ('think', 716079),\n",
       " ('still', 694767),\n",
       " ('go', 667647),\n",
       " ('face', 657549),\n",
       " ('way', 656362),\n",
       " ('severus', 655653),\n",
       " ('room', 648483),\n",
       " ('hand', 639610),\n",
       " ('ginny', 639543),\n",
       " ('sirius', 630217),\n",
       " ('something', 623393),\n",
       " ('want', 613213),\n",
       " ('potter', 608396),\n",
       " ('thought', 608149),\n",
       " ('right', 603543),\n",
       " ('snape', 600467),\n",
       " ('away', 580724),\n",
       " ('much', 578715),\n",
       " ('two', 572215),\n",
       " ('look', 566540),\n",
       " ('never', 559460),\n",
       " ('really', 526364),\n",
       " ('knew', 524840),\n",
       " ('first', 523467),\n",
       " ('made', 513183),\n",
       " ('let', 513130),\n",
       " ('good', 510087),\n",
       " ('malfoy', 486334),\n",
       " ('wand', 482517),\n",
       " ('little', 481391),\n",
       " ('felt', 476097),\n",
       " ('dumbledore', 472844),\n",
       " ('turned', 472763),\n",
       " ('james', 468947),\n",
       " ('come', 461147),\n",
       " ('got', 446945),\n",
       " ('make', 446018),\n",
       " ('took', 436164),\n",
       " ('remus', 433776),\n",
       " ('lily', 423882),\n",
       " ('though', 421472),\n",
       " ('sure', 414025),\n",
       " ('looking', 412947),\n",
       " ('say', 412107),\n",
       " ('door', 408796),\n",
       " ('tell', 407274),\n",
       " ('dark', 407087),\n",
       " ('take', 406712),\n",
       " ('us', 404371),\n",
       " ('long', 400953),\n",
       " ('voice', 397148),\n",
       " ('voldemort', 396693),\n",
       " ('last', 395133),\n",
       " ('told', 387987),\n",
       " ('need', 385193),\n",
       " ('left', 382492),\n",
       " ('yes', 381412),\n",
       " ('man', 378306),\n",
       " ('wanted', 369171),\n",
       " ('anything', 367354),\n",
       " ('next', 357422),\n",
       " ('oh', 355362),\n",
       " ('came', 343141),\n",
       " ('love', 341285),\n",
       " ('nodded', 341059),\n",
       " ('moment', 336220),\n",
       " ('people', 334999),\n",
       " ('year', 333338),\n",
       " ('saw', 333047),\n",
       " ('another', 332659),\n",
       " ('things', 328450),\n",
       " ('went', 325856),\n",
       " ('hands', 325015),\n",
       " ('death', 324143),\n",
       " ('help', 322672),\n",
       " ('day', 322607),\n",
       " ('enough', 320944),\n",
       " ('boy', 316913),\n",
       " ('smiled', 312584),\n",
       " ('professor', 311845),\n",
       " ('mind', 311632),\n",
       " ('nothing', 308573),\n",
       " ('ever', 308525),\n",
       " ('found', 306832),\n",
       " ('hair', 301575),\n",
       " ('always', 300553),\n",
       " ('house', 299252),\n",
       " ('find', 297437),\n",
       " ('bit', 296606),\n",
       " ('seemed', 293976),\n",
       " ('behind', 293761),\n",
       " ('hogwarts', 292077),\n",
       " ('thing', 287879),\n",
       " ('bed', 287639),\n",
       " ('trying', 284261),\n",
       " ('feel', 281511),\n",
       " ('put', 281299),\n",
       " ('started', 281286),\n",
       " ('life', 279701),\n",
       " ('since', 278135),\n",
       " ('black', 277103),\n",
       " ('night', 276927),\n",
       " ('heard', 273446),\n",
       " ('years', 269698),\n",
       " ('smile', 268328),\n",
       " ('without', 266676),\n",
       " ('side', 266635),\n",
       " ('better', 265331),\n",
       " ('magic', 263904),\n",
       " ('gave', 262515),\n",
       " ('might', 261477),\n",
       " ('weasley', 260521),\n",
       " ('everyone', 257575),\n",
       " ('father', 256195),\n",
       " ('sat', 254242),\n",
       " ('began', 253560),\n",
       " ('someone', 253201),\n",
       " ('almost', 252376),\n",
       " ('walked', 250456),\n",
       " ('done', 248115),\n",
       " ('finally', 247509),\n",
       " ('already', 246985),\n",
       " ('three', 246206),\n",
       " ('tried', 245227),\n",
       " ('place', 245212),\n",
       " ('every', 243955),\n",
       " ('stood', 242650),\n",
       " ('friends', 241073),\n",
       " ('everything', 240961),\n",
       " ('lord', 238907),\n",
       " ('front', 238700),\n",
       " ('small', 238338),\n",
       " ('pulled', 238162),\n",
       " ('also', 237641),\n",
       " ('quickly', 237230),\n",
       " ('course', 236434),\n",
       " ('body', 234851),\n",
       " ('girl', 234442),\n",
       " ('keep', 234441),\n",
       " ('best', 232186),\n",
       " ('towards', 228042),\n",
       " ('old', 224188),\n",
       " ('else', 223388),\n",
       " ('arms', 223093),\n",
       " ('neville', 221532),\n",
       " ('table', 221110),\n",
       " ('mean', 219659),\n",
       " ('give', 219635),\n",
       " ('work', 219427),\n",
       " ('family', 219201),\n",
       " ('sorry', 217530),\n",
       " ('albus', 216669),\n",
       " ('end', 215669),\n",
       " ('please', 215640),\n",
       " ('great', 215253),\n",
       " ('many', 214172),\n",
       " ('world', 214004),\n",
       " ('mother', 213938),\n",
       " ('school', 213614),\n",
       " ('lucius', 211132),\n",
       " ('together', 209583),\n",
       " ('new', 208980),\n",
       " ('stop', 208088),\n",
       " ('quite', 207916),\n",
       " ('happened', 206185),\n",
       " ('open', 206000),\n",
       " ('leave', 205871),\n",
       " ('maybe', 204900),\n",
       " ('replied', 204740),\n",
       " ('mouth', 203652),\n",
       " ('soon', 202643),\n",
       " ('must', 202614),\n",
       " ('yet', 202305),\n",
       " ('floor', 198391),\n",
       " ('later', 198083),\n",
       " ('getting', 196775),\n",
       " ('able', 195327),\n",
       " ('words', 194066),\n",
       " ('name', 193608),\n",
       " ('arm', 193454),\n",
       " ('hard', 193444),\n",
       " ('friend', 191664),\n",
       " ('lips', 191123),\n",
       " ('least', 190824),\n",
       " ('mr', 188900),\n",
       " ('feeling', 188644),\n",
       " ('actually', 188220),\n",
       " ('suddenly', 187313),\n",
       " ('anyone', 187245),\n",
       " ('seen', 186447),\n",
       " ('slowly', 186398),\n",
       " ('sighed', 184346),\n",
       " ('luna', 183894),\n",
       " ('spell', 183553),\n",
       " ('talk', 182824),\n",
       " ('making', 180959),\n",
       " ('shook', 179552),\n",
       " ('gone', 178634),\n",
       " ('light', 177510),\n",
       " ('rather', 177136),\n",
       " ('george', 177020),\n",
       " ('believe', 176735),\n",
       " ('second', 176435),\n",
       " ('blood', 176289),\n",
       " ('home', 175614),\n",
       " ('far', 175378),\n",
       " ('probably', 175349),\n",
       " ('held', 175034),\n",
       " ('granger', 173448),\n",
       " ('used', 173343),\n",
       " ('inside', 172833),\n",
       " ('opened', 171417),\n",
       " ('rest', 170746),\n",
       " ('taking', 170213),\n",
       " ('fred', 169566),\n",
       " ('muggle', 167888),\n",
       " ('half', 167888),\n",
       " ('stopped', 167220),\n",
       " ('hear', 167022),\n",
       " ('rose', 166667),\n",
       " ('idea', 166373),\n",
       " ('whispered', 166282),\n",
       " ('thank', 165984),\n",
       " ('coming', 164758),\n",
       " ('try', 164591),\n",
       " ('called', 164568),\n",
       " ('breath', 164378),\n",
       " ('care', 164329),\n",
       " ('across', 163994),\n",
       " ('slightly', 163288),\n",
       " ('tom', 163148),\n",
       " ('parents', 162405),\n",
       " ('yeah', 162074),\n",
       " ('students', 161343),\n",
       " ('needed', 161040),\n",
       " ('close', 160032),\n",
       " ('ask', 159987),\n",
       " ('laughed', 159593),\n",
       " ('may', 159088),\n",
       " ('slytherin', 158939),\n",
       " ('heart', 158902),\n",
       " ('watched', 158108),\n",
       " ('use', 157961),\n",
       " ('gryffindor', 157866),\n",
       " ('part', 157447),\n",
       " ('sitting', 156915),\n",
       " ('continued', 156904),\n",
       " ('morning', 156325),\n",
       " ('happy', 154648),\n",
       " ('feet', 154147),\n",
       " ('lot', 153864),\n",
       " ('red', 152758),\n",
       " ('pain', 152528),\n",
       " ('book', 150402),\n",
       " ('okay', 149465),\n",
       " ('remember', 149201),\n",
       " ('fact', 148719),\n",
       " ('hall', 148682),\n",
       " ('past', 148101),\n",
       " ('stared', 146469),\n",
       " ('reached', 146040),\n",
       " ('chapter', 145804),\n",
       " ('fine', 145801),\n",
       " ('along', 145702),\n",
       " ('however', 145443),\n",
       " ('ministry', 145354),\n",
       " ('thinking', 144814),\n",
       " ('wizard', 144046),\n",
       " ('wrong', 144040),\n",
       " ('onto', 143493),\n",
       " ('hope', 143027),\n",
       " ('alone', 142740),\n",
       " ('shoulder', 142477),\n",
       " ('read', 141693),\n",
       " ('set', 141629),\n",
       " ('bad', 140423),\n",
       " ('moved', 140051),\n",
       " ('standing', 139679),\n",
       " ('either', 139234),\n",
       " ('dead', 138573),\n",
       " ('chest', 138472),\n",
       " ('talking', 137429),\n",
       " ('fell', 137260),\n",
       " ('decided', 137247),\n",
       " ('minutes', 136055),\n",
       " ('potion', 136031),\n",
       " ('stay', 135863),\n",
       " ('ran', 135280),\n",
       " ('hurt', 134729),\n",
       " ('young', 134417),\n",
       " ('understand', 134273),\n",
       " ('mcgonagall', 134019),\n",
       " ('point', 133882),\n",
       " ('air', 133855),\n",
       " ('fingers', 133804),\n",
       " ('person', 133079),\n",
       " ('instead', 132965),\n",
       " ('kill', 132825),\n",
       " ('caught', 132816),\n",
       " ('matter', 132641),\n",
       " ('woman', 132271),\n",
       " ('potions', 132245),\n",
       " ('miss', 132187),\n",
       " ('days', 132130),\n",
       " ('others', 131070),\n",
       " ('ready', 130447),\n",
       " ('kiss', 130412),\n",
       " ('tonks', 130354),\n",
       " ('tears', 130240),\n",
       " ('ground', 130160),\n",
       " ('son', 129642),\n",
       " ('kept', 129227),\n",
       " ('taken', 128172),\n",
       " ('times', 128063),\n",
       " ('wait', 127776),\n",
       " ('full', 127736),\n",
       " ('deep', 127544),\n",
       " ('order', 127434),\n",
       " ('forward', 126988),\n",
       " ('curse', 126937),\n",
       " ('closed', 126766),\n",
       " ('eaters', 126091),\n",
       " ('noticed', 125396),\n",
       " ('story', 125127),\n",
       " ('magical', 124696),\n",
       " ('kind', 123685),\n",
       " ('lost', 123411),\n",
       " ('reason', 123372),\n",
       " ('raised', 123044),\n",
       " ('sleep', 122338),\n",
       " ('sound', 121845),\n",
       " ('thanks', 121228),\n",
       " ('move', 120528),\n",
       " ('blaise', 119960),\n",
       " ('eye', 119487),\n",
       " ('wall', 119083),\n",
       " ('different', 119067),\n",
       " ('whole', 119042),\n",
       " ('office', 117303),\n",
       " ('bellatrix', 117277),\n",
       " ('several', 116970),\n",
       " ('question', 116022),\n",
       " ('start', 115962),\n",
       " ('followed', 115446),\n",
       " ('word', 114961),\n",
       " ('turn', 114690),\n",
       " ('large', 114094),\n",
       " ('perhaps', 113696),\n",
       " ('anyway', 113625),\n",
       " ('class', 113580),\n",
       " ('answer', 113033),\n",
       " ('outside', 112944),\n",
       " ('holding', 112869),\n",
       " ('attention', 112384),\n",
       " ('hit', 112115),\n",
       " ('lupin', 111414),\n",
       " ('chair', 111398),\n",
       " ('answered', 111255),\n",
       " ('completely', 110957),\n",
       " ('cold', 110823),\n",
       " ('green', 110694),\n",
       " ('exactly', 110675),\n",
       " ('scorpius', 110516),\n",
       " ('quietly', 110265),\n",
       " ('waiting', 110251),\n",
       " ('four', 109428),\n",
       " ('immediately', 108626),\n",
       " ('mum', 108315),\n",
       " ('ago', 108168),\n",
       " ('minerva', 108027),\n",
       " ('robes', 107798),\n",
       " ('spoke', 107632),\n",
       " ('saying', 107626),\n",
       " ('longer', 107480),\n",
       " ('watching', 106933),\n",
       " ('today', 106907),\n",
       " ('leaving', 106728),\n",
       " ('stepped', 106291),\n",
       " ('true', 106153),\n",
       " ('child', 106088),\n",
       " ('seeing', 105600),\n",
       " ('hold', 105464),\n",
       " ('master', 105358),\n",
       " ('fire', 105307),\n",
       " ('pansy', 105043),\n",
       " ('staring', 104987),\n",
       " ('surprised', 104941),\n",
       " ('given', 104730),\n",
       " ('nearly', 104704),\n",
       " ('silence', 104538),\n",
       " ('witch', 104451),\n",
       " ('dad', 104352),\n",
       " ('turning', 103984),\n",
       " ('neck', 103934),\n",
       " ('nice', 103811),\n",
       " ('softly', 103689),\n",
       " ('headmaster', 103327),\n",
       " ('finished', 103176),\n",
       " ('meant', 102411),\n",
       " ('brought', 102043),\n",
       " ('closer', 102036),\n",
       " ('simply', 101834),\n",
       " ('war', 101008),\n",
       " ('grabbed', 100650),\n",
       " ('show', 100448),\n",
       " ('hell', 100387),\n",
       " ('top', 99986),\n",
       " ('bloody', 99647),\n",
       " ('grinned', 99617),\n",
       " ('call', 99603),\n",
       " ('charm', 99507),\n",
       " ('managed', 99364),\n",
       " ('realized', 99214),\n",
       " ('change', 99118),\n",
       " ('says', 98993),\n",
       " ('narcissa', 98939),\n",
       " ('looks', 98929),\n",
       " ('brother', 98833),\n",
       " ('quidditch', 98425),\n",
       " ('running', 98043),\n",
       " ('children', 97891),\n",
       " ('kissed', 97438),\n",
       " ('killed', 97325),\n",
       " ('chance', 97261),\n",
       " ('speak', 96922),\n",
       " ('common', 96782),\n",
       " ('shut', 96718),\n",
       " ('skin', 96715),\n",
       " ('mrs', 96430),\n",
       " ('week', 96179),\n",
       " ('sent', 95005),\n",
       " ('known', 94872),\n",
       " ('alright', 94214),\n",
       " ('white', 94075),\n",
       " ('added', 93861),\n",
       " ('pointed', 93783),\n",
       " ('run', 93751),\n",
       " ('castle', 93664),\n",
       " ('rolled', 93468),\n",
       " ('five', 93375),\n",
       " ('met', 93361),\n",
       " ('less', 93325),\n",
       " ('molly', 92834),\n",
       " ('expression', 92805),\n",
       " ('boys', 92763),\n",
       " ('supposed', 92605),\n",
       " ('walking', 92498),\n",
       " ('whatever', 92452),\n",
       " ('returned', 92442),\n",
       " ('knowing', 92264),\n",
       " ('fight', 92184),\n",
       " ('muttered', 92146),\n",
       " ('hours', 92087),\n",
       " ('cast', 91978),\n",
       " ('appeared', 91859),\n",
       " ('girls', 91619),\n",
       " ('leaned', 91520),\n",
       " ('giving', 91238),\n",
       " ('upon', 90746),\n",
       " ('happen', 90621),\n",
       " ('books', 90511),\n",
       " ('water', 90308),\n",
       " ('thoughts', 90117),\n",
       " ('pretty', 89937),\n",
       " ('shrugged', 89936),\n",
       " ('sort', 89724),\n",
       " ('spells', 89242),\n",
       " ('guess', 89208),\n",
       " ('throat', 89105),\n",
       " ('letter', 88886),\n",
       " ('gently', 88837),\n",
       " ('real', 88788),\n",
       " ('worry', 88535),\n",
       " ('big', 88349),\n",
       " ('pushed', 88075),\n",
       " ('loved', 88030),\n",
       " ('hagrid', 87461),\n",
       " ('stairs', 87414),\n",
       " ('possible', 87267),\n",
       " ('surprise', 87094),\n",
       " ('couple', 86862),\n",
       " ('glanced', 86713),\n",
       " ('meet', 86088),\n",
       " ('passed', 85884),\n",
       " ('seem', 85869),\n",
       " ('fear', 85572),\n",
       " ('bill', 85367),\n",
       " ('beside', 85145),\n",
       " ('watch', 84880),\n",
       " ('become', 84871),\n",
       " ('power', 84861),\n",
       " ('desk', 84732),\n",
       " ('sit', 84699),\n",
       " ('stand', 84692),\n",
       " ('placed', 84678),\n",
       " ('smiling', 84287),\n",
       " ('dinner', 84191),\n",
       " ('merlin', 83730),\n",
       " ('late', 83696),\n",
       " ('although', 83419),\n",
       " ('sense', 83389),\n",
       " ('safe', 83379),\n",
       " ('corner', 83264),\n",
       " ('toward', 83222),\n",
       " ('die', 82778),\n",
       " ('sir', 82413),\n",
       " ('wizards', 82240),\n",
       " ('stupid', 82099),\n",
       " ('bring', 81879),\n",
       " ('walk', 81856),\n",
       " ('eater', 81557),\n",
       " ('soft', 81437),\n",
       " ('baby', 81202),\n",
       " ('shot', 81076),\n",
       " ('anymore', 80722),\n",
       " ('break', 80593),\n",
       " ('kitchen', 80498),\n",
       " ('knows', 80396),\n",
       " ('snapped', 80365),\n",
       " ('agreed', 80117),\n",
       " ('wondered', 80064),\n",
       " ('short', 80036),\n",
       " ('near', 79656),\n",
       " ('wish', 79463),\n",
       " ('free', 79424),\n",
       " ('quiet', 79326),\n",
       " ('telling', 79311),\n",
       " ('blue', 79041),\n",
       " ('group', 78655),\n",
       " ('changed', 78602),\n",
       " ('window', 78561),\n",
       " ('sister', 78541),\n",
       " ('laugh', 78506),\n",
       " ('peter', 78438),\n",
       " ('moving', 78415),\n",
       " ('pulling', 78201),\n",
       " ('return', 78043),\n",
       " ('charlie', 78028),\n",
       " ('plan', 77886),\n",
       " ('angry', 77839),\n",
       " ('case', 77632),\n",
       " ('trust', 77182),\n",
       " ('explained', 77045),\n",
       " ('reading', 76938),\n",
       " ('dropped', 76829),\n",
       " ('shoulders', 76586),\n",
       " ('barely', 76486),\n",
       " ('sight', 76084),\n",
       " ('gaze', 75974),\n",
       " ('cut', 75736),\n",
       " ('live', 75692),\n",
       " ('beautiful', 75164),\n",
       " ('especially', 75124),\n",
       " ('died', 74943),\n",
       " ('figure', 74782),\n",
       " ('within', 74655),\n",
       " ('working', 74641),\n",
       " ('clear', 74634),\n",
       " ('christmas', 74621),\n",
       " ('shaking', 74471),\n",
       " ('legs', 74337),\n",
       " ('tonight', 74335),\n",
       " ('memory', 74324),\n",
       " ('worried', 74289),\n",
       " ('control', 74173),\n",
       " ('months', 74164),\n",
       " ('spent', 74126),\n",
       " ('seat', 74092),\n",
       " ('entire', 73873),\n",
       " ('shouted', 73871),\n",
       " ('dear', 73788),\n",
       " ('living', 73725),\n",
       " ('frowned', 73412),\n",
       " ('straight', 72997),\n",
       " ('fall', 72961),\n",
       " ('stomach', 72958),\n",
       " ('hour', 72908),\n",
       " ('conversation', 72717),\n",
       " ('stone', 72589),\n",
       " ('wizarding', 72049),\n",
       " ('allowed', 71913),\n",
       " ('form', 71904),\n",
       " ('fun', 71892),\n",
       " ('remembered', 71773),\n",
       " ('tone', 71757),\n",
       " ('afraid', 71664),\n",
       " ('filled', 71410),\n",
       " ('entered', 71349),\n",
       " ('picked', 71214),\n",
       " ('anger', 71067),\n",
       " ('glad', 70958),\n",
       " ('touch', 70842),\n",
       " ('broke', 70829),\n",
       " ('quick', 70826),\n",
       " ('step', 70643),\n",
       " ('silent', 70309),\n",
       " ('nose', 70224),\n",
       " ('truth', 70172),\n",
       " ('play', 70093),\n",
       " ('grin', 70038),\n",
       " ('meeting', 69811),\n",
       " ('cried', 69784),\n",
       " ('hey', 69595),\n",
       " ('laughing', 69564),\n",
       " ('auror', 69479),\n",
       " ('important', 69421),\n",
       " ('smirked', 69180),\n",
       " ('certain', 69093),\n",
       " ('warm', 68887),\n",
       " ('empty', 68840),\n",
       " ('none', 68768),\n",
       " ('became', 68593),\n",
       " ('team', 68504),\n",
       " ('weeks', 68462),\n",
       " ('high', 68190),\n",
       " ('using', 67988),\n",
       " ('food', 67988),\n",
       " ('percy', 67885),\n",
       " ('older', 67539),\n",
       " ('fleur', 67353),\n",
       " ('hate', 67233),\n",
       " ('expected', 67021),\n",
       " ('wide', 66946),\n",
       " ('threw', 66803),\n",
       " ('cheek', 66505),\n",
       " ('breakfast', 66301),\n",
       " ('yelled', 66294),\n",
       " ('worse', 66253),\n",
       " ('elf', 66177),\n",
       " ('problem', 66068),\n",
       " ('perfect', 65761),\n",
       " ('teddy', 65700),\n",
       " ('ones', 65636),\n",
       " ('cloak', 65609),\n",
       " ('clearly', 65588),\n",
       " ('n', 65580),\n",
       " ('memories', 65417),\n",
       " ('waited', 65172),\n",
       " ('shock', 64885),\n",
       " ('obviously', 64805),\n",
       " ('liked', 64736),\n",
       " ('ten', 64683),\n",
       " ('wife', 64628),\n",
       " ('alive', 64533),\n",
       " ('arrived', 64433),\n",
       " ('sometimes', 64423),\n",
       " ('riddle', 64406),\n",
       " ('certainly', 64339),\n",
       " ('note', 64220),\n",
       " ('carefully', 63946),\n",
       " ('summer', 63774),\n",
       " ('despite', 63538),\n",
       " ('glass', 63377),\n",
       " ('job', 63292),\n",
       " ('gotten', 63282),\n",
       " ('information', 63244),\n",
       " ('wrapped', 63233),\n",
       " ('daphne', 63219),\n",
       " ('loud', 63183),\n",
       " ('forced', 62993),\n",
       " ('madam', 62936),\n",
       " ('except', 62902),\n",
       " ('ear', 62874),\n",
       " ('strong', 62720),\n",
       " ('clothes', 62612),\n",
       " ('tomorrow', 62567),\n",
       " ('battle', 62477),\n",
       " ('library', 62467),\n",
       " ('tea', 62455),\n",
       " ('deal', 62414),\n",
       " ('strange', 62198),\n",
       " ('trouble', 62178),\n",
       " ('calm', 62173),\n",
       " ('worked', 61961),\n",
       " ('minute', 61823),\n",
       " ('confused', 61808),\n",
       " ('owl', 61770),\n",
       " ('middle', 61666),\n",
       " ('headed', 61392),\n",
       " ('easy', 61289),\n",
       " ('evening', 61278),\n",
       " ('normal', 61127),\n",
       " ('daughter', 61029),\n",
       " ('mine', 60988),\n",
       " ('shirt', 60680),\n",
       " ('parchment', 60642),\n",
       " ('lay', 60600),\n",
       " ('secret', 60585),\n",
       " ('seems', 60555),\n",
       " ('makes', 60477),\n",
       " ('twins', 60457),\n",
       " ('paused', 60414),\n",
       " ('apparently', 60413),\n",
       " ('notice', 60309),\n",
       " ('line', 60085),\n",
       " ('tired', 59950),\n",
       " ('suppose', 59728),\n",
       " ('moments', 59673),\n",
       " ('broom', 59654),\n",
       " ('somehow', 59182),\n",
       " ('led', 59114),\n",
       " ('tongue', 58955),\n",
       " ('broken', 58907),\n",
       " ('usual', 58743),\n",
       " ('lying', 58710),\n",
       " ('promise', 58686),\n",
       " ('cup', 58664),\n",
       " ('piece', 58560),\n",
       " ('pale', 58413),\n",
       " ('men', 58205),\n",
       " ('arthur', 58125),\n",
       " ('chuckled', 58087),\n",
       " ('familiar', 57891),\n",
       " ('sounded', 57848),\n",
       " ('questions', 57839),\n",
       " ('game', 57802),\n",
       " ('attack', 57784),\n",
       " ('doubt', 57764),\n",
       " ('mate', 57580),\n",
       " ('muggles', 57500),\n",
       " ('mad', 57492),\n",
       " ('save', 57480),\n",
       " ('wonder', 57458),\n",
       " ('means', 57455),\n",
       " ('finger', 57298),\n",
       " ('bright', 57247),\n",
       " ('helped', 57210),\n",
       " ('uncle', 57062),\n",
       " ('bella', 57011),\n",
       " ('explain', 56926),\n",
       " ('aurors', 56857),\n",
       " ('pressed', 56809),\n",
       " ('gasped', 56723),\n",
       " ('minister', 56705),\n",
       " ('third', 56688),\n",
       " ('jumped', 56631),\n",
       " ('charms', 56588),\n",
       " ('hissed', 56568),\n",
       " ('situation', 56493),\n",
       " ('hospital', 56298),\n",
       " ('whether', 56141),\n",
       " ('position', 56053),\n",
       " ('lifted', 56028),\n",
       " ('glared', 56005),\n",
       " ('manor', 55831),\n",
       " ('moody', 55733),\n",
       " ('covered', 55680),\n",
       " ('fast', 55600),\n",
       " ('catch', 55335),\n",
       " ('shall', 55248),\n",
       " ('seconds', 55219),\n",
       " ('wants', 55065),\n",
       " ('often', 54993),\n",
       " ('asleep', 54770),\n",
       " ('asking', 54634),\n",
       " ('early', 54633),\n",
       " ('dobby', 54364),\n",
       " ('teeth', 54356),\n",
       " ('pomfrey', 53989),\n",
       " ('listen', 53953),\n",
       " ('wearing', 53933),\n",
       " ('neither', 53751),\n",
       " ('al', 53654),\n",
       " ('bag', 53593),\n",
       " ('write', 53519),\n",
       " ('follow', 53423),\n",
       " ('kingsley', 53415),\n",
       " ('following', 53349),\n",
       " ('sigh', 53320),\n",
       " ('forget', 53302),\n",
       " ('letting', 53290),\n",
       " ('besides', 53278),\n",
       " ('screamed', 53229),\n",
       " ('soul', 53227),\n",
       " ('truly', 53173),\n",
       " ('pull', 53163),\n",
       " ('mark', 53150),\n",
       " ('student', 52990),\n",
       " ('ended', 52751),\n",
       " ('beginning', 52726),\n",
       " ('keeping', 52725),\n",
       " ('fighting', 52652),\n",
       " ('hoped', 52640),\n",
       " ('playing', 52526),\n",
       " ('flew', 52321),\n",
       " ('likely', 52264),\n",
       " ('silver', 52229),\n",
       " ('brown', 52216),\n",
       " ('wondering', 52161),\n",
       " ('eyebrow', 52122),\n",
       " ('husband', 52093),\n",
       " ('guys', 52075),\n",
       " ('easily', 52050),\n",
       " ('lip', 52048),\n",
       " ('direction', 52008),\n",
       " ('usually', 51999),\n",
       " ('hot', 51871),\n",
       " ('learn', 51857),\n",
       " ('hated', 51847),\n",
       " ('crying', 51792),\n",
       " ('future', 51768),\n",
       " ('ah', 51731),\n",
       " ('starting', 51697),\n",
       " ('edge', 51564),\n",
       " ('somewhere', 51552),\n",
       " ('eat', 51480),\n",
       " ('enjoy', 51475),\n",
       " ('flying', 51328),\n",
       " ('six', 51325),\n",
       " ('self', 51271),\n",
       " ('azkaban', 50967),\n",
       " ('low', 50893),\n",
       " ('shocked', 50754),\n",
       " ('offered', 50736),\n",
       " ('cheeks', 50577),\n",
       " ('cry', 50517),\n",
       " ('hoping', 50509),\n",
       " ('falling', 50478),\n",
       " ('damn', 50429),\n",
       " ('age', 50424),\n",
       " ('powerful', 50388),\n",
       " ('tightly', 50349),\n",
       " ('hide', 50281),\n",
       " ('serious', 50247),\n",
       " ('earlier', 50236),\n",
       " ('send', 50206),\n",
       " ('knees', 50147),\n",
       " ('money', 50007),\n",
       " ('train', 49983),\n",
       " ('drink', 49836),\n",
       " ('missed', 49826),\n",
       " ('pair', 49793),\n",
       " ('ravenclaw', 49786),\n",
       " ('pocket', 49758),\n",
       " ('disappeared', 49744),\n",
       " ('speaking', 49739),\n",
       " ('choice', 49686),\n",
       " ('god', 49580),\n",
       " ('lived', 49532),\n",
       " ('aware', 49515),\n",
       " ('single', 49469),\n",
       " ('spot', 49403),\n",
       " ('expect', 49216),\n",
       " ('definitely', 49178),\n",
       " ('wake', 49124),\n",
       " ('handed', 48944),\n",
       " ('putting', 48808),\n",
       " ('present', 48758),\n",
       " ('eventually', 48750),\n",
       " ('hug', 48749),\n",
       " ('aunt', 48652),\n",
       " ('bedroom', 48531),\n",
       " ('forest', 48464),\n",
       " ('mirror', 48428),\n",
       " ('killing', 48341),\n",
       " ('ears', 48292),\n",
       " ('dress', 48171),\n",
       " ('simple', 48102),\n",
       " ('scared', 47933),\n",
       " ('check', 47890),\n",
       " ('waved', 47791),\n",
       " ('laughter', 47776),\n",
       " ('paper', 47704),\n",
       " ('continue', 47581),\n",
       " ('admit', 47576),\n",
       " ('join', 47365),\n",
       " ('sounds', 47345),\n",
       " ('exclaimed', 47232),\n",
       " ('feelings', 47147),\n",
       " ('force', 47096),\n",
       " ('breathing', 47048),\n",
       " ('blinked', 46983),\n",
       " ('corridor', 46976),\n",
       " ('box', 46921),\n",
       " ('slipped', 46775),\n",
       " ('relief', 46715),\n",
       " ('showed', 46700),\n",
       " ('forehead', 46574),\n",
       " ('sleeping', 46554),\n",
       " ('writing', 46547),\n",
       " ('smirk', 46477),\n",
       " ('doors', 46438),\n",
       " ('younger', 46387),\n",
       " ('final', 46301),\n",
       " ('news', 46246),\n",
       " ('wands', 46225),\n",
       " ('cannot', 46119),\n",
       " ('murmured', 46093),\n",
       " ('protect', 45957),\n",
       " ('causing', 45865),\n",
       " ('ok', 45809),\n",
       " ('ball', 45734),\n",
       " ('bathroom', 45654),\n",
       " ('indeed', 45634),\n",
       " ('snake', 45455),\n",
       " ('kissing', 45430),\n",
       " ('twenty', 45411),\n",
       " ('wards', 45191),\n",
       " ('dangerous', 45148),\n",
       " ('steps', 45138),\n",
       " ('business', 45114),\n",
       " ('seamus', 45063),\n",
       " ('lunch', 44976),\n",
       " ('dean', 44921),\n",
       " ('glance', 44833),\n",
       " ('evil', 44804),\n",
       " ('obvious', 44691),\n",
       " ('alley', 44691),\n",
       " ('cause', 44595),\n",
       " ('entrance', 44577),\n",
       " ('dream', 44574),\n",
       " ('party', 44492),\n",
       " ('sudden', 44492),\n",
       " ('stayed', 44429),\n",
       " ('ring', 44422),\n",
       " ('cedric', 44401),\n",
       " ('married', 44395),\n",
       " ('busy', 44393),\n",
       " ('foot', 44386),\n",
       " ('apart', 44378),\n",
       " ('dragon', 44354),\n",
       " ('visit', 44243),\n",
       " ('touched', 44215),\n",
       " ('fuck', 44205),\n",
       " ('honestly', 44169),\n",
       " ('difficult', 44167),\n",
       " ('needs', 44163),\n",
       " ('fault', 43996),\n",
       " ('imagine', 43992),\n",
       " ('drew', 43951),\n",
       " ('number', 43950),\n",
       " ('blonde', 43917),\n",
       " ('stuff', 43868),\n",
       " ('burst', 43738),\n",
       " ('leaning', 43700),\n",
       " ('walls', 43693),\n",
       " ('aside', 43677),\n",
       " ('human', 43638),\n",
       " ('groaned', 43617),\n",
       " ('slytherins', 43603),\n",
       " ('crowd', 43585),\n",
       " ('darkness', 43544),\n",
       " ('interrupted', 43353),\n",
       " ('hello', 43204),\n",
       " ('couch', 43193),\n",
       " ('silently', 43163),\n",
       " ('odd', 43156),\n",
       " ('teacher', 43108),\n",
       " ('learned', 43099),\n",
       " ('remained', 43079),\n",
       " ('tower', 43069),\n",
       " ('stated', 42866),\n",
       " ('werewolf', 42864),\n",
       " ('match', 42863),\n",
       " ('stuck', 42854),\n",
       " ('ahead', 42720),\n",
       " ('lavender', 42715),\n",
       " ('date', 42646),\n",
       " ('tight', 42581),\n",
       " ('growled', 42577),\n",
       " ('wanting', 42504),\n",
       " ('spend', 42476),\n",
       " ('allow', 42298),\n",
       " ('born', 42257),\n",
       " ('lose', 42233),\n",
       " ('points', 42097),\n",
       " ('finish', 42034),\n",
       " ('relationship', 42010),\n",
       " ('grew', 41992),\n",
       " ('act', 41951),\n",
       " ('heavy', 41948),\n",
       " ('hiding', 41928),\n",
       " ('realised', 41922),\n",
       " ('regulus', 41778),\n",
       " ('umbridge', 41764),\n",
       " ('response', 41752),\n",
       " ('shop', 41733),\n",
       " ('crossed', 41707)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Топ-10 по частоте: имен, пар имя + фамилия, пар вида ''профессор'' + имя / фамилия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем, что если в тексте попадается Harry Potter, то вносим его только в имя + фамилия. Если встречаем professor Snape, то учитываем только в частоте профессоров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NER = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ners(text, ner, names, full_names, prof_names):\n",
    "    ners = ner(text)\n",
    "\n",
    "    for entity in ners.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            name = entity.text\n",
    "            if entity.start != 0:\n",
    "                prev_token = ners[entity.start - 1]\n",
    "                if prev_token.text.lower() == 'professor':\n",
    "                    prof_names[name] += 1\n",
    "                    continue\n",
    "            if len(name.split()) >= 2:\n",
    "                full_names[name] += 1\n",
    "            else:\n",
    "                names[name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/36225 [01:44<25:35:01,  2.55s/it] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45221c84237e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_NER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mget_ners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-148b49d96398>\u001b[0m in \u001b[0;36mget_ners\u001b[0;34m(text, ner, names, full_names, prof_names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprof_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PERSON'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.precompute_hiddens.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/spacy/_ml.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         Yf = self.ops.gemm(\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = defaultdict(int)\n",
    "full_names = defaultdict(int)\n",
    "prof_names = defaultdict(int)\n",
    "\n",
    "ner = spacy.load('en')\n",
    "\n",
    "for path in tqdm(os.listdir(RAW_TEXTS_DIR)):\n",
    "    full_path = os.path.join(RAW_TEXTS_DIR, path)\n",
    "\n",
    "    with open(full_path, 'r') as f:\n",
    "        text = f.read()\n",
    "        step = min(MAX_NER, len(text))\n",
    "        for i in range(0, len(text) - step + 1, step):\n",
    "            get_ners(text[i: i + step], ner, names, full_names, prof_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = sorted(names.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_full_names = sorted(full_names.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_prof_names = sorted(prof_names.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_10_names.pickle', 'wb') as f:\n",
    "    pickle.dump([top_names, top_full_names, top_prof_names], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постройте тематическую модель по корпусу HPAC.\n",
    "\n",
    "## Найдите еще что-то интересное в корпусе (что-то специфичное для фанфиков или фентези-тематики)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бейзлайн (fastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over and under sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
